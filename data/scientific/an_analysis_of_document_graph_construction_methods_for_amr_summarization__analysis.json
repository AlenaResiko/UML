{
  "authors": [
    "Fei-Tzin Lee",
    "Chris Kedzie",
    "Nakul Verma",
    "Kathleen McKeown"
  ],
  "date_published": "2021-11-27",
  "raw_tex": "\\section{Analysis}\n\\begin{table*}[t]\n   \\centering\n   \\begin{tabular}{c|p{10cm}}\n   \\toprule Error type & Example sentence fragment pair that produces error\\\\ \\midrule\n   \\multirow{2}{*}{Concept conflation (surface)} & ...required to inform any person whose \\textbf{assets} are being frozen... \\\\\n   & ...an European Union decision to freeze the \\textbf{assets} of the People's Mujahadeen of Iran.\\\\ \\hline\n   \\multirow{2}{*}{Concept conflation (hidden)} & ...the foreign \\textbf{minister} of India... \\\\\n   & ...the foreign \\textbf{minister} of China...\\\\\\bottomrule\n   \\end{tabular}\n   \\caption{Examples of concept conflation errors in concept merging.}\n   \\label{tab:small-errors}\n\\end{table*}\n\n\\subsection{Concept error analysis}\nWe identify nodes that concept merging clustered incorrectly using our annotated alignments and perform a manual inspection of concept merging errors on the development set, identifying five types of common errors: stopword conflation, missing synonyms, name skipping, conflation of surface concepts and conflation of hidden concepts. We present examples of the latter two kinds of error in \\autoref{tab:small-errors}, and examples of all types of error in \\autoref{sec:error-analysis}.\n\nWhile the first two types of errors can be resolved with straightforward fixes (e.g., holding out stopwords when merging), and the third and fourth can be resolved using text-based coreference, the final and most complex type of error involves incorrectly merging AMR nodes that do not explicitly appear in the text, and thus cannot be resolved simply by performing coreference on the text itself. This error often occurs when there are multiple entities in the text of a concept type that induces a large implicit structure, such as the foreign ministers in \\autoref{fig:merge}. Hidden concept conflation requires linking text coreference to the graph structure of the AMR, as the person-focused and combined merge strategies are designed to do.\n\n\\subsection{The role of coreference}\n\\label{sec:analysis-person}\nPerhaps the most curious observation from these results is that while person merging has worse performance in both the cluster evaluation and on node selection than either unmerged or concept merged graphs - in fact, it has strikingly poor scores under merge cluster metrics - using it together with concept merging in the combined strategy yields by far the best results. This suggests that these two methods have strengths that are complementary.\n\n\\begin{table}[]\n   \\centering\n   \\begin{tabular}{c c}\n   \\toprule\n   Method & Proportion of merged nodes\\\\\n   \\midrule\n   Unmerged & 0\\\\\n   Concept & 0.509 \\\\\n   Person & 0.012 \\\\\n   Combined & 0.572 \\\\\n   \\bottomrule\n   \\end{tabular}\n   \\caption{Average proportion of document nodes that are merged for each strategy, over the development set.}\n   \\label{tab:merge_proportion}\n\\end{table}\n\nWhen we examine the clusters generated by person merging, we find that much of the poor performance can simply be attributed to the fact that it hardly merges any nodes at all (see \\autoref{tab:merge_proportion}). This is unsurprising: there are relatively few nodes that occur both under a person node and within a coreference cluster, and even fewer that share a label with another person-descendant node in the same coreference cluster.\n\nIn this case, the benefit of using person merging as a first step in conjunction with\nconcept merging is not so much that it itself brings higher-quality merges, but rather that it takes a number of low-quality merges out of consideration by removing them from the pool of as yet unmerged nodes.\n\nWe further note that since the decision to merge nodes can only be made between nodes of the same label in the combined strategy, with additional restrictions between nodes in person subtrees that do not co-refer, we would expect its recall to be no higher than that of concept merging, which merges nodes with the same label without co-reference-based restriction.\n\nThe fact that there is also a large improvement in recall indicates that concept merging misses a sizable proportion of merges because of some condition that it does not share with combined merging. The only such difference is the initial name and date collapse step. This means that adding an identifying name to a node's label indeed has the adverse effect of preventing it from being merged with other instances of the same entity that were not similarly referred to by name in many cases, as described in \\autoref{sec:error-analysis}.\n\nThus, combined merging also averts this type of error by replacing the name collapse step with co-reference-based subtree matching.\n\n\\subsection{Generated summaries}\nThe automatic metric scores indicate that while the combined merge strategy is slightly better than concept merging, the unmerged strategy outperforms both of the others. This is fairly surprising, as there does not seem to be any intuitive reason that leaving the AMR unmerged should be better for generation than merging it correctly. However, a manual inspection of the validation set reveals that the unmerged strategy generally yields much longer linearized inputs to the generator, and in fact on the validation set simply passing in the linearized AMR for the entire document graph yields better scores on automatic metrics than using the selected nodes from any merge strategy; we hypothesize that BART is powerful enough to identify redundant information even in AMR, which seemingly obviates the merging step.\n\nHowever, the human evaluation tells a more nuanced story. While unmerged inputs yield the most salient outputs - supporting the hypothesis that BART performs its own internal pruning of redundant information - using the combined merge strategy improves faithfulness on person-related information, which suggests that narrowing down the field of consideration in the input helps it focus better on the actual information it is supposed to summarize rather than adding in details to fill in the gaps. The merge strategies are roughly evenly matched on fluency, but combined merge also has a slight edge here.",
  "title": "An analysis of document graph construction methods for AMR summarization"
}
