{
  "authors": [
    "Szymon Snoeck",
    "Noah Bergam",
    "Nakul Verma"
  ],
  "date_published": "2025-08-09",
  "raw_tex": "\n\\begin{figure}[t]\\centering\\includegraphics[width\\textwidth]{img/tsne-neighpres-k1.png}\\label{fig:practical_preservation}\\caption{Failure of one-nearest neighbor graph preservation in t-SNE visualizations of (left) a mixture of high-dimensional Gaussians, (center) a mixture of high-dimensional Cauchy distributions, and (right) a subset of the digits dataset. A red edge indicates a pair of points that were nearest neighbors in the original dataset but are no longer neighbors in the output. A blue edge indicates pairs of points that were not neighbors in the original and are neighbors in the output embedding.}\\label{fig.realDataNeighbors}\\end{figure}\n\n\nWhy study \\(\\alpha\\)-preservation? It is a natural formulation of the basic desideratum of data visualization: \\textit{compress the data while keeping neighbors close and non-neighbors far}. \n\nGiven the pervasive use of data visualization techniques like t-SNE and UMAP which ``just seem to work'' in practice, it is tempting to believe that data visualization is essentially a solved problem. Our analysis of \\(\\alpha\\)-preservation reveals some evidence to the contrary: in many situations of practical interest, including when data has extremely pronounced cluster structure, visualizing neighbor and non-neighbor relationships fundamentally requires high dimensions.\\textcolor{red}{s}. n output to reside in a metric of non-constant dimension. \\st{which scales with the number of points rather than the intrinsic dimension of the data.\n\nOne may wonder how the incompressibility results presented in this work reconcile? with existing ``positive'' findings on constant-dimensional embeddings. For instance, \n\\citet{arora2018analysis} established that two-dimensional t-SNE plots do in fact successfully \\emph{visualize} well-separated clustered data, in effect implying good cluster neighborhood separation in constant dimensions. Similarly, \\citet{sarkar2011low} gave a construction on how to embed trees arbitrarily well in two-dimensional hyperbolic spaces, again implying good neighbor preservation in constant dimensions. \nThough at a cursory glace these results seem to contradict our findings. Note however they are DEAD WRONG!\n\n\n\nOne may wonder how the incompressibility results presented in this work square with more ``positive'' findings regarding the possibility of constant-dimensional data visualizations. \\todo{This paragraph is missing a feeling of being natural.} \n\\citet{arora2018analysis}, for instance, established that two-dimensional t-SNE plots successfully visualize well-clustered data. In effect, their result speaks to the fact that \\(\\alpha\\)-preservation of extremely clustered neighborhood graphs (i.e.\\ \\(q0\\) and \n\\(p1\\), in the context of Definition \\ref{def:pp_model}) can be done in constant dimensions. Our results show that any introduction of noise, between or within clusters, requires strictly greater than constant dimension (specifically \\(\\Omega(\\log k)\\) for \\(q> 0\\) and \\(\\Omega(\\log n)\\) for \\(p<1\\)) for neighborhood preservability. Similarly, \\citet{sarkar2011low} gave a construction on how to embed trees arbitrarily well in two-dimensional hyperbolic spaces, again implying good neighbor preservation in constant dimensions. At first glance, this seems to contradict the findings of Lemma \\ref{lem:preservation-hammer}, which would imply that \\(\\Omega(\\log n)\\) doubling dimensions are necessary to \\(\\alpha\\)-preserve balanced, constant-degree trees. Note, however, that a constant-dimensional hyperbolic space does not have a constant \\emph{doubling} dimension. that doubling dimension is simply not a proxy for hyperbolic space dimension. \n\nOne can think of \\((\\alpha\\leq 1)\\)-preservation as a relaxation of \\((1/\\alpha)\\)-distortion embedding (indeed, a bounded distortion embedding has correspondingly bounded preservation, see Observation \\ref{obs:DistortionImpliesPreservationMetric}). Since neighborhood preservation is fundamentally a \\textit{local} concept, it is particularly well-suited to embedding geometric objects such as manifolds that are characterized by their local structure (indeed, our results can be extended and sharpened for such data). In the grand scheme of metric embedding desiderata, preservation is refreshingly lenient compared to low-distortion. For instance, \\(1\\)-preservation (the hardest form of \\(\\alpha\\leq 1\\) preservation) is possible for any graph in \\(\\ell_2\\), whereas \\(1\\)-distortion (the hardest form of low-distortion embedding, of course) is very much not possible: even some graph metrics of constant doubling dimension require \\(\\sqrt{\\log n}\\)-distortion in \\(\\ell_2\\) \\citep{gupta2003bounded}! the relaxation from low-distortion to preservation makes certain embedding problems of interest easier. allows for significantly better parameters. \n\n\nFor instance, there exist graphs with constant doubling dimension \\textcolor{red}{that} require $\\Omega(\\sqrt{\\log n})$-distortion to embed in Euclidean space, whereas all graphs can be \\(1\\)-preserved in \\(\\ell_2\\) \\citep{gupta2003bounded}.\\todo{i dont understand what you want to say}\n\\citet{gupta2003bounded} showed the existence of graphs with doubling dimension which can be $1$-preserved in Euclidean space, see Proposition \\ref{prop:chiGBasedUpperBound}, but requires $\\Omega(\\sqrt{\\log n})$ distortion. \\todo{This paragraph talking about the importance of local preservation should proceed the paragraph where we say we need better algorithms for it.}\n\n\\st{preserving geodesic distance and therefore intrinsic manifold structure. This understanding can be formalized and extended to potentially tighten our analysis of $\\alpha$-preservation dimension, see Appendix}Unlike low-distortion embeddings, preservation gives up large absolute distances; however, by preserving small distances, it effectively maintains the geodesic distances, making it quite suitable for manifold learning. \nWe hope to formalize this understanding in further study of preservation.   \n\nOur notion of neighborhood preservation \n\nIt is worth comparing our notion of neighborhood preservation to the more classically-studied notion of low-distortion (or near-isometric) embedding. There is a ket \n\n\nas the solution to the following optimization problem generated by the graph:the minimization of a very difficult objective\u2013\u2013\u2013the doubling dimension\u2013\u2013\u2013with respect to very basic linear constraints (ensuring that the interpoint distance)\n\\begin{align*}\n   \\dim_\\alpha(G)   \\min_{D\\in \\mathbb{R}^{n\\times n}} \\dim D   \\ \\ \\ \\text{ s.t. } \\ \\ &\\forall i,j,k \\in [n] \\ \\ \\ \\ \\ \\   D_{ij} + D_{jk} \\geq D_{ik}   D_{ki} \\geq 0 \\ \\ \\text{(metric constraints)}\\\\\n   &\\forall (i,j) \\in E(G) \\ \\ D_{ij} \\leq 1 \\ \\ \\ \\ \\ \\ \\ \\forall (i,j) \\notin E(G) \\ \\ D_{ij} > \\alpha\n\\end{align*}\nThis problem has linear constraints but an objective which is both non-convex and (as far as folklore goes )NP-hard to compute \\ref{}. For preservation in \\(\\ell_2\\) this can be rewritten into a semidefinite program with a rank objective, which can naturally be relaxed to a more computationally tractable trace objective. An empirical study of this program could give us a sense of the \\(\\alpha\\)-preservation dimension of real-world datasets.\n\nThere are many avenues of further investigation. For instance, it is natural to consider \\emph{approximate \\(\\alpha\\)-preservation}: given some neighborhood graph and a fixed target dimension $d$, what fraction of neighborhoods can be $\\alpha$-preserved in $d$? Does this relaxation dramatically change the stringent rather bleak \nlower bounds of this work? If so, then answering this question for real-world datasets would allow us calibrate our expectations for data visualization on a case-by-case basis. \n\nMore generally, it is tempting to pursue an \\emph{algorithmic realization of \\(\\alpha\\)-preservation}. One can think of the construction of an optimal \\(\\alpha\\)-preservation as the minimization of a very difficult objective\u2013\u2013the doubling dimension\u2013\u2013with respect to basic linear constraints\u2013\u2013dictating the metric structure and the \\(\\alpha\\)-preservation thresholds. For preservation in \\(\\ell_2\\) this optimization (as well as its approximate counterpart) can be approximated by a semidefinite program. Are there alternative, less obvious algorithms? Our study of \\(\\alpha\\)-preservation suggests that certain graph statistics, including \\(C(G)\\), \\(P(G)\\), and the graph spectrum, can help to quantify \\(\\alpha\\)-preservation. \n\nPursuing algorithms for \\(\\alpha\\)-preservation brings us full circle. Our study was motivated by the idea that popular data visualization methods boil down to extracting a useful neighborhood graph and optimizing some sort of relaxed \\(\\alpha\\)-preservation-esque objective in a fixed dimension. The jury is still out: does this practice constitute a provably effective approximation algorithm for a well-defined problem? Or is the problem, even with all the standard relaxations, simply too hard?What are the strengths and limitations of this approach?\n\\todo{meh...}\n\n",
  "title": "Compressibility Barriers to Neighborhood-Preserving Data Visualizations"
}
