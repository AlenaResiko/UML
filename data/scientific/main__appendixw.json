{
  "authors": [
    "Iddo Drori",
    "Gaston Longhitano",
    "Mao Mao",
    "Seunghwan Hyun",
    "Yuke Zhang",
    "Sungjun Park",
    "Zachary Meeks",
    "Xin-Yu Zhang",
    "Ben Segev",
    "Howard Yong",
    "Nakul Verma",
    "Avi Shporer",
    "Alon Amit",
    "Madeleine Udell"
  ],
  "date_published": "2025-02-14",
  "raw_tex": "\\section{Meta Learning Agent Graph Experiments}\n\\label{appendix:W}\n\nLet $x$ be a problem, and \\(\\pi_{\\theta}(y \\mid x)\\) the probability distribution over responses \\(y\\) generated by a model with parameters \\(\\theta\\). This is any one of the $K$ models or methods. \nWe begin with a human-generated agent graph or pipeline $f$, which provides a starting state for a structured approach for solving the problem $x$, returning an answer $y   f(x)$. \n\n\\paragraph{Agent-graph representation using Rivet.}\nWe represent the pipeline $f$ as an agent graph using the Rivet framework \\footnote{\\url{https://rivet.ironcladapp.com}}. This agent graph consists of modular components that act on the input $x$ in a sequential or parallel manner, resulting in a final output $y$. Each run of the agent graph produces a trace $z   \\text{Trace}(f, x)$ which is the internal trace, or log, of the agent's execution steps \\footnote{\\url{https://gentrace.ai}}. When the graph is executed on input $x$, we obtain both the response and trace $(y,z)\\bigl(f(x),\\,\\text{Trace}(f, x)\\bigr)$.\n\n\\paragraph{Meta-learning to improve the pipeline.}\nAfter running the agent graph on the problem $x$, we collect the tuple \n$\\bigl(f,\\,x,\\,z,\\,y\\bigr)$, of the graph representation $f$, problem $x$, execution trace $z$, and response $y$. We use this to meta-learn an improved agent-graph pipeline $f'$. We define a meta-learning operator $g$ such that $f'   g\\bigl(f,\\,y,\\,z,\\,x\\bigr)$. The meta-learner $g$ takes as input the graph representation $f$, observed trace $z$, problem $x$, and the final response $y$ and outputs a revised graph $f'$ with adjustments or modifications to nodes, sub-agent selection or ordering, or modified data flow.\n\n\\paragraph{Integration with model policies.}\nThe pipeline $f$ may query a model distribution \\(\\pi_\\theta(y \\mid x)\\) at various steps. For example, modules (or sub-agents) in $f$ typically call a model to propose partial solutions or substeps. Additionally, the final output $y$ itself may be fused with, or determined by, the model's predictions:\n\\begin{equation}\ny \\;\\; \n\\begin{cases}\nf(x), & \\text{(pure agent-graph pipeline)}, \\\\\n\\arg\\max_{y'} \\pi_\\theta(y' \\mid x), & \\text{(pure model-based policy)}, \\\\\n\\text{Hybrid}(f(x),\\, \\pi_\\theta(y \\mid x)), & \\text{(agent-model combination)},\n\\end{cases}\n\\end{equation}\nwhere $\\text{Hybrid}$ denotes a joint decision that takes into account both the deterministic pipeline's recommendation and the stochastic model predictions.\n\n\\paragraph{Iterative refinement loop.}\nOnce the meta-learner $g$ updates the pipeline to $f'$, we may iteratively repeat the process on problem instances $\\{x_i\\}$, to produce a sequence of pipelines $f^{(t)}$. This allows the agent-graph pipeline to evolve and improve over time, guided by collected traces and outputs.\n\n\n\n\\begin{table}[h]\n\\caption{Comparisons of different levels of meta-learning on inference time agents.}\n\\label{tab:meta}\n\\vskip 0.15in\n\\begin{center}\n\\begin{scriptsize}\n\\begin{sc}\n\\begin{tabular}{lccc}\n\\toprule\nGraph & Entity & Operation \\\\\n\\midrule\nFixed & hyper-parameters & search \\\\\nFixed & prompts & add/remove/edit \\\\\nFixed & data & add/remove \\\\\nFixed & code & add/remove/edit \\\\\nDynamic & edges & add/remove \\\\\nDynamic & nodes & add/remove \\\\\n\\bottomrule\n\\end{tabular}\n\\end{sc}\n\\end{scriptsize}\n\\end{center}\n\\vskip -0.1in\n\\end{table}\n",
  "title": "main"
}
