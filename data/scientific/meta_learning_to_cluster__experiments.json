{
  "authors": [
    "Yibo Jiang",
    "Nakul Verma"
  ],
  "date_published": "2019-10-30",
  "raw_tex": "\n\n\nWe evaluate the efficacy of our proposed LSTM network architecture for Meta-Clustering by performing various synthetic and real-world experiments that measures how various aspects of the input data (such as representation dimension, number of true clusters, etc.) affect the prediction quality.\n\nWe start by describing our synthetic data generation process.\n\n\n\n\n\n\\subsection{Synthetic Dataset Generation}\n\\label{sec:synth_data}\n\\textbf{Generating Gaussian-shaped clusters.} The most basic kind of clustering are those where each cluster is generated from a multivariate Gaussian distribution with a random mean and covariance. Specifically, to generate $K$ clusters in $d$ dimensions, we sample the means $\\mu_i$ and covariances $\\Sigma_i$ ($i$ denotes the cluster id) as\n\\begin{align*}\n\\mu_i &\\sim \\textup{Uniform}([\\theta,\\theta]^d), \\textrm{ and } \n\\;\\;\\;\\;\\; \\Sigma_i   : \\hat{C}_i^\\mathsf{T}\\hat{C}_i, \n\\;\\;\\; \\textrm{ where} \\\\\n\\hat{C}_i & \\textup{orth}(C_i)/ k_i, \\,\nC_i :[c_1 \\ldots c_d ], \\\\\nc_j &\\sim \\textup{Gaussian}(0,I), \\,\nk_i \\sim \\textup{Uniform}(\\alpha,\\alpha+\\beta).\n\\end{align*}\n\n$\\textup{orth}(\\cdot)$ denotes the orthogonalization of $\\cdot$, and parameters $\\alpha$ and $\\beta$ control the magnitude of the entries in the covariance matrix. Smaller $\\alpha$ and $\\beta$ results in overlapping clusters, and thus results in harder to distinguish clusters.\n\n\\textbf{Generating curved shaped clusters by adding simple nonlinearities.}\nMere Gaussian shaped data generation may not capture the complex nature of some real world data.\nWe therefore introduce simple nonlinearities to our synthetically generated random Gaussian clusters. For any point $x$ and two arbitrary coordinates $p,q$, we apply the following:\n\\begin{align*}\n&\\hat{x}_p   \\cos(t)x_p + \\sin(t)x_q, \\;\n\\hat{x}_q   -\\sin(t)x_p + \\cos(t)x_q \\\\\n &\\textrm{where } t   \\pi r/k_r, \\, r\\|z\\|, \\, z   [x_p,x_q ], \\\\\n&k_r   \\sim \\textup{Uniform}(\\alpha_r,\\alpha_r+\\beta_r).\n\\end{align*}\n\n\nWe apply this transformation to points in a cluster several times (each time selecting two different coordinates). \nSee Figure~\\ref{fig:sample_data} for example datasets generated by this process.\n\n\\begin{figure}\n\\centering\n   \\begin{tabular}{@{}cc@{}}\n   \\includegraphics[width.25\\textwidth]{figures/sample/easy/4.png} \n   \\includegraphics[width.25\\textwidth]{figures/sample/medium/10.png}   \\\\\n   \\includegraphics[width.33\\textwidth]{figures/sample/medium/7.png} \\\\\n   \\includegraphics[width.25\\textwidth]{figures/sample/3-classes/5.png} \n   \\includegraphics[width.33\\textwidth]{figures/sample/2.png} \\hspace{-0.18in}\n   \\includegraphics[width.23\\textwidth]{figures/sample/3.png}\n   \\includegraphics[width.25\\textwidth]{figures/sample/4-classes/4.png}\n   \\\\\n   \\end{tabular}\n   \\caption{Sample synthetic datasets generated by our procedure.}\n   \\label{fig:sample_data}\n\\end{figure}\n\n\\textbf{Assigning the cluster identity.}\nWhile we can assign labels to the randomly generated clusters with any permutation, the extra degree of freedom makes the training harder. Instead, the clusters are sorted by the first dimension of their mean vectors and the cluster ids are assigned sequentially. \\TODO{better/fancier sorting: I have one. Not sure if it is effective or not. Will include if there is space}\n\n \\begin{figure}[t]\n \\centering\n \\includegraphics[width\\linewidth]{figures/compare/real_fake.png}\n \\caption{Performance of meta clustering on MNIST when trained with a mixture of real and synthetic dataset. Error rate and normalized mutual information reported are both averaged over 100 samples.}\n \\label{fig:real_fake}\n \\end{figure}\n\n \\begin{table}[h]\n   \\centering\n   \\caption{Average error rate of meta-clustering on synthetic dataset compared to other standard clustering methods with different feature dimensions (100 samples). *: Covariance matrix scaled so that it is more competitive.}\n   \\begin{tabular}{cccccc}\n   \\toprule\n   & $k$-means & Kernel $k$-means & Spectral Clustering & DBSCAN   & Meta-Clustering\\\\\n   \\midrule\n   Dim2 &0.186\t&0.290\t&0.191\t&0.470\t& \\textbf{0.0847} \\\\\n   \\midrule\n   Dim3 & 0.186\t&0.283\t&0.166\t&0.451\t&\\textbf{0.107} \\\\\n   \\midrule\n   Dim5 & 0.147\t&0.136\t&0.171\t&0.554\t&\\textbf{0.116} \\\\\n   \\midrule\n   Dim10* & 0.266 &0.321 &0.339 &0.724 &\\textbf{0.0519} \\\\\n   \\midrule\n   Dim20* & 0.326 &\\textbf{0.223} &0.392 &0.889 &0.265 \\\\\n   \\bottomrule\n   \\end{tabular}\n   \\label{tab:dim}\n \\end{table}\n\n\n\n\n\n\n \\textbf{Optional scaling and filtering}\n\\subsection{Baseline Methods and Evaluation Criteria}\nWe use several popular clustering methods as baselines to compare the quality of our proposed Meta-Clustering.\n\\begin{itemize}\n\\item $k$-means -- it is arguably the most popular clustering method; the number of clusters needs to be prespecified; can only find convex clusters. \n\\item Kernelized $k$-means -- it is a nonlinear extension to $k$-means that can potentially find arbitrary shaped clusters. We use radial basis function (rbf) kernel for all our experiments.\n\\item Spectral Clustering   -- it is another very popular nonlinear extension to $k$-means that can potentially find arbitrary shaped clusters. \n\\item DBSCAN -- it is a density based clustering that can find arbitrary shaped clusters, and is robust to noise. The user does not need to specity the number of clusters. It is most effective on low-dimensional clustering problems.\n\\item {DEC} -- it is a deep learning based clustering algorithm \\citep{xie2016unsupervised}. It employs an auto-encoder as feature extractor and uses soft assignment to calculate loss to optimize. Because auto-encoder needs to be trained for each dataset, the runtime can be long when presented with samples from multiple datasets and it is most effective when dataset is large.   required by the auto-encoder training.\n\\end{itemize} \nThe reported results use the best parameter settings for each of the baseline methods.   The clustering quality is evaluated using the 0-1 loss.\nSince any permutation of labels should not change the clustering quality, the best permutation of the predictions also needs to be taken into account Specifically\n \\begin{equation*}\n   $   \\textup{ER} : {\\sum_{i1}^m \\textbf{1}[s_i \\neq \\textup{map}(r_i)]}/{m}$,\n\\end{equation*}\n where $m$ is the total number of datapoints, $s_i$ and $r_i$ are the true and the predicted label of the $i$th datapoint. map$(\\cdot)$ denotes the best permutation \nusing the   \nKuhn-Munkres algorithm.\n\n \\textbf{Normalized Mutual Information (NMI).} \\TODO{Considering error rate only}NMI is a popular measure to quantify classification accuracy for multi-category problems, especially when different classes have different number of datapoints \\citep{DBLP:journals/tkde/CaiHH11}. Let $C$ and $C'$ be the real- and algorithm predicted- labels. Then NMI is be computed as: \n \\begin{align*}\n   \\textup{NMI}(C,C') &: \\frac{\\textup{MI}(C,C')}{\\textup{Avg}(\\textup{H}(C),\\textup{H}(C'))}\n \\end{align*}\n where $\\textup{MI}(\\cdot,\\cdot)$ and $\\textup{H}(\\cdot)$ denote the information theoretic quantities: mutual information and entropy respectively.\n\n\n\n\n \\begin{table*}[ht]\n   \\centering\n   \\caption{Average error rate and normalized mutual information of meta-Clustering on synthetic dataset compared to other standard clustering methods when the test data is scaled (100 samples)}\n   \\begin{tabular}{|c|c|c|c|c|c|}\n   \\hline\n   Method & $k$-means & Kernel $k$-means & Spectral Clustering & DBSCAN   & Meta-Clustering\\\\\n   \\hline\n   ER & \\textbf{0.0686}\t& 0.1739 & 0.2368 & 0.4584 & 0.1041 \\\\\n   \\hline\n   NMI & \\textbf{0.659} & 0.431 & 0.478 & 0.117 & 0.555 \\\\\n   \\hline\n   \\end{tabular}\n   \\label{tab:2-D-Scale}\n \\end{table*}\n\n\n\\begin{figure*}[b]\n\\centering\n\\begin{subfigure}\n   \\centering\n   \\begin{tabular}{@{}cccc@{}}\n   \\includegraphics[width0.3\\textwidth]{figures/adaptive/local_2.png} &\n   \\includegraphics[width0.3\\textwidth]{figures/adaptive/local_3_2.png} &\n   \\includegraphics[width0.3\\textwidth]{figures/adaptive/local_4_2.png} \n   \\end{tabular}\n   \\caption{Clustering results when varying number of clusters in the test task.}\n   \\label{fig:adaptive}\n\\end{subfigure}\n\n\\end{figure*}\n\\subsection{Experiments on Synthetic Datasets}\n\\label{sec:syn-exp}\nWe first evaluate our model on synthetic test datasets by training on synthetic datasets. Training and test datasets are generated the same way but drawn independently.\n\n\\begin{table*}\n   \\centering\n   \\caption{Average Error rate of meta-clustering on synthetic dataset compared to other standard clustering methods \n   (100 samples).}\n   \\begin{tabular}{ccccccc}\n   \\toprule\n   $k$-means & \\tabsplit{Kernel \\\\ $k$-means} & \\tabsplit{Spectral \\\\ Clustering} & DBSCAN   & DEC & Meta-Clustering & \\tabsplit{Meta-Clustering \\\\ (scaled)}\\\\\n   \\midrule\n   0.17\t& 0.29 & 0.17 & 0.48 & 0.18 & \\textbf{0.08} & 0.10\\\\\n   \\bottomrule\n   \\end{tabular}\n   \\label{tab:2-D}\n\\end{table*}\n\n\\subsubsection{2-D case study}\n\\label{sec:2-d-case}\n\\textbf{2-D case study.}\nTable~\\ref{tab:2-D} shows the performance of our meta-clustering model when compared to the other benchmark clustering methods. The model is trained on synthetic dataset with two clusters. Since the datasets generated are arbitrary shaped clusters (and not necessarily convex), centroid based methods that operate in the input representation like $k$-means is not expected to work well. Remarkably even more flexible methods such as spectral clustering do not yield significant improvement over $k$-means either. Our meta-clustering method (second to last column in Table~\\ref{tab:2-D}) performs the best, demonstrating the power of the meta-learning framework: when trained on similar related tasks. Meta-clustering in some sense \\emph{learns} the right notion of cluster loss and can outperform even the most popular cluster losses for simplest of tasks.\n\n \\vspace{-0.2in}\n\n\\subsubsection{Location and Scale Invariance}\n\\textbf{Location and Scale Invariance.}\nMeta clustering can also do well on datasets that are not limited to where the training data resides in the representation space. In this experiment, our data points during test were translated and scalded by a factor of $3$. As shown in the last column of Table~\\ref{tab:2-D}, meta-clustering still performs comparably. This indirectly suggests that meta-clustering does not cluster simply based on what is observed in the training data, and generalizes well. This observation is further corroborated in Section \\ref{sec:real_data} by testing the synthetically trained model on real datasets and Section \\ref{sec:open-ml} by training and testing on real datasets of different distributions.\n\n\n\\subsubsection{Adapting to the Number of Clusters}\n\\label{sec:adaptive}\n\n\\textbf{Adapting to the Number of Clusters.}\nIt is worth noting that our model has the ability to approximate the number of clusters in the new clustering task. \nThough, there is still a limit on the maximum number of clusters (determined by the output dimension of our LSTM architecture). \nEven though there is a constraint on the number of clusters our model can output based on the output dimension of LSTM, the clustering result is not necessarily limited to that pre-determined number. \nIn this experiment, our model is constrained to output up to 5 clusters. The training data consists of synthetically generated clusters with the number of clusters varying between 1 and 5. We sample more training datasets with higher number of clusters to prevent training models that are biased towards returning fewer clusters.\nFigure~\\ref{fig:adaptive} shows the results on test datasets, showing the ability of our meta-clustering architecture to adapt to given dataset.\n\n\n\n\nsuggests that meta clustering has some ability to adapt based on the data given.\n\nduring training, the dataset is generated to have arbitrary number of clusters from $1-5$. Importantly, datasets with more clusters should have higher chances of being generated preventing trained models to develop the tendency to output degenerate clustering results. Test dataset is also generated the same way but drawn independently.   \n Interestingly, the first plot suggests that even though out model may not provide exact clusters as provided, the result can still be reasonable. \n\n\n \\TODO{the following two section may be uncessary, if I can get openml to work with multi-clusters or high-dimensions}\n \\subsubsection{Varying Feature Dimensions}\n We also verify how the quality of our model scales with the representation dimension of the dataset. Table~\\ref{tab:dim} demonstrates that our model remains competitive across different dimensions. As expected, DBSCAN's quality drops significantly, while other benchmarks remain relatively robust.\n\n \\subsubsection{Varying the Number of Clusters}\n Finally we test the performance of our model on different number of clusters. Unlike the ``Adaptive\" case (cf.\\ Section \\ref{sec:adaptive}), here we are not testing if the model can determine the right number of clusters. Instead, here we want to focus on whether the clustering performance degrades as one increases the number of clusters. \n Table~\\ref{tab:multi} shows that the model remains competitive in this case as well.\n\nare we test our model with different number of clusters. All the datasets used here are generated from 100 data points regardless of the cluster number. Again, our model is competitive in each scenario as evident by Table~\\ref{tab:multi}.\n \\begin{table*}[htb]\n   \\centering\n   \\caption{Average normalized mutual information of meta-clustering on synthetic dataset compared to other standard clustering methods with different number of clusters (100 samples).}\n   \\begin{tabular}{cccccc}\n   \\toprule\n   & $k$-means & Kernel $k$-means & Spectral Clustering & DBSCAN   & Meta-Clustering\\\\\n   \\midrule\n   2 clusters &0.285\t&0.305\t&0.292\t&0.213\t&\\textbf{0.490} \\\\\n   \\midrule\n   3 clusters & 0.311\t&0.317\t&0.339\t&0.082\t&\\textbf{0.343} \\\\\n   \\midrule\n   4 clusters & 0.435\t&0.480\t&0.459\t&0.385\t&\\textbf{0.470} \\\\\n   \\midrule\n   5 clusters & 0.337\t&0.256\t&\\textbf{0.349}\t&0.103\t&0.334 \\\\\n   \\midrule\n   6 clusters & 0.367\t&0.362\t&0.361\t&0.356\t&\\textbf{0.373} \\\\\n   \\bottomrule\n   \\end{tabular}\n   \\label{tab:multi}\n \\end{table*}\n\n Fig \\ref{fig:original} and Fig \\ref{fig:scale_shift} showcase two sample cluster results over iterations on 2-D datasets. In Fig \\ref{fig:original}, it is obvious that the cluster assignment is being improved across iterations. It still misses points in the middle of this $L$-shaped dataset. However, the assignments for those points are even ambiguous to human. \n\n On the other hand, meta-clustering is not restricted to performing well only on datasets approximately in the same area as training data. Based on the data generation procedure presented in section 4.1, each coordinate of data points is roughly within the range $[-1,1]$. Fig \\ref{fig:scale_shift} shows that meta-clustering can still perform clustering even when the data are scaled and shifted to different ranges. This indirectly suggests that meta-clustering does not cluster simply based on what is observed in the training data. In the next subsection, we will also present its generalization on real datasets.\n\n \\begin{figure*}[htb]\n \\centering\n \\includegraphics[width\\linewidth]{compare/original.png}\n \\caption{Change of cluster assignment over different iterations on synthetic dataset}\n \\label{fig:original}\n \\end{figure*}\n\n \\begin{figure*}[htb]\n \\centering\n \\includegraphics[width\\linewidth]{compare/scale_shift.png}\n \\caption{Change of cluster assignment over different iterations on synthetic dataset with additional shifting and scaling}\n \\label{fig:scale_shift}\n \\end{figure*}\n\n \\subsubsection{Performance on Synthetic Dataset with Different Feature Dimensions}\n\n \\begin{figure}[htb]\n \\centering\n \\includegraphics[width\\linewidth]{compare/high_dim.png}\n \\caption{Performance of Meta cluster on synthetic dataset with different feature dimensions}\n \\label{fig:high_dim}\n \\end{figure}\n\n Fig~\\ref{fig:high_dim} shows the average error rate across iterations on synthetic datasets. It can be shown that the error rate drops across iterations. $\\beta$ and $\\alpha$ are set to be $5$ in this case. Based on this figure, we conclude that meta-clustering can perform well on synthetic datasets regardless of dimensions. \n\n \\subsubsection{Mutli-class Clustering on Synthetic Dataset}\n\n \\begin{figure}[htb]\n \\centering\n \\includegraphics[width\\linewidth]{compare/mult_clas.png}\n \\caption{Performance of Meta cluster on synthetic dataset with different number of clusters}\n \\label{fig:multi_class}\n \\end{figure}\n\n Fig~\\ref{fig:multi_class} shows the average NMI value trajectory across iterations. The value presented here is averaged over 200 samples for each test. $\\alpha$ and $\\beta$ are set to 30 in this case to avoid possible overlap between clusters. It is evident that the meta-clustering gradually finds a better cluster assignment. Also, average NMI values are lower with more clusters possibly because the chance of overlapping clusters increase under the same data generation parameters when there are more clusters. \n\n\n\n\n\n\n\n\n\n\n\\vspace{-0.1in}\n\\subsection{Training with Synthetic Data}\n\\label{sec:real_data}\nWe also evaluate our method on several real datasets. Our primary goal is to evaluate how our clustering algorithm performs on real datasets even when the training is done on synthetic datasets. Training configurations (number of clusters, feature dimensions, number of data points) for synthetic data will match the test case.\n\n\\begin{table*}\n   \\centering\n   \\caption{Error rates on UKM, MNIST and IRIS datasets (trained on synthetic data)compared to other standard clustering methods\n   }\n\n   \\begin{tabular}{ccccccc}\n   \\toprule\n   Method & $k$-means & Ker. $k$-means & Spec. Clust. & DBSCAN   & DEC & Meta Clust. \\\\\n   \\midrule\n   UKM & 0.31\t&\\textbf{0.26}\t&0.28\t&0.49 & 0.28\t&\\textbf{0.26} \\\\\n   \\midrule\n   MNIST & 0.35\t& 0.33\t& 0.40\t& 0.49\t& 0.46 & \\textbf{0.32} \\\\\n   \\midrule\n   IRS & 0.19\t&0.23\t&0.19\t&0.38 & 0.24 & \\textbf{0.09} \\\\\n   \\bottomrule\n   \\end{tabular}\n   \\label{tab:MNIST}\n\\end{table*}\n\n\n\\subsubsection{User Knowledge Modeling}\n\\textit{User Knowledge Modeling}\n\\label{ukm}\nUser Knowledge Modeling\n\\citep{Kahraman:2013:DIK:2400768.2401504} is a dataset about the students' knowledge on the subject of Electrical DC Machines. Each example has five attributes describing various aspects of a student's knowledge. Students are classified into four knowledge levels: ``very low\", ``low\", ``medium\" and ``high\".\n\nDuring training, we randomly generate 100 synthetic datasets per epoch and train for 50 epochs. Each synthetic datasets consists of 100 data points and 2 clusters. The generation process is the same as described in Section \\ref{sec:synth_data}. For test, we sample 100 points from ``low\" and ``high\" classes, and evaluate the trained model by averaging the error rates of 100 runs. \nPCA is applied to reduce feature dimension to 2. \nThe result is shown in Table \\ref{tab:MNIST}. Notice that meta-clustering gets competitive error rates.   only performing worse than Kernel $k$-means.\n\n\\subsubsection{MNIST}\n\n\\textit{MNIST database} \\citep{726791} of handwritten digits has 70,000 examples. The digits have been size-normalized and centered in $28\\times28$ pixel size images. \nWe preprocess the dataset by applying PCA down to 2 dimensions. \ndownimages by converting them into a vector of length 784 and then zero-center the vectors. We also do dimension reduction using PCA before feeding the data to avoid the curse of dimensionality. \n{We trained the model on synthetic datasets the same way as described for UKM dataset} but with 1000 data points per dataset. During test, we sample 1000 data points from two randomly selected two digits each time and the error rate shown in Table~\\ref{tab:MNIST} is the average over 100 samples.\nNotice that every data point is first projected to 2 dimension through PCA. \nTable~\\ref{tab:MNIST} shows that meta clustering outperforms other standard clustering methods. For a fair comparison, the auto-encoder in DEC is re-trained for each sample because each clustering algorithm should only look at the sample given. Thus, the auto-encoder may not be sufficiently trained.}\n\n\\subsubsection{Iris}\n\\textit{Iris dataset} \\citep{Dua:2017} contains three classes with a total of 150 data points and 4 features. The model is trained similarly as before with 150 data points per synthetic dataset and tested on the 150 iris data points without sampling.\nBefore performing clustering, all the data points has been reduced to dimension of 2 using PCA. \nTable~\\ref{tab:MNIST} shows that our model performs much better than the standard benchmarks. \nDuring training, all the datasets are randomly generated. \nFigure~\\ref{fig:iris} shows the clustering result on this data in detail. Notice that our method (right plot) can uncover the two clusters on the right much better than $k$-means (left plot).\n\n\\begin{figure*}\n\\setlength\\tabcolsep{2pt}\n\\centering\n   \\begin{tabular}{@{}ccc@{}}\n   \\includegraphics[width.33\\textwidth]{figures/compare/iris/kmeans.png}&\n   \\includegraphics[width.33\\textwidth]{figures/compare/iris/Orginal.png} &\n   \\includegraphics[width.33\\textwidth]{figures/compare/iris/metaCluster.png} \n   \\end{tabular}\n   \\caption{ \\footnotesize Visualized comparison of $k$-means and meta-clustering on Iris dataset. Visualization made by projecting the data onto the top two principal component. Center: Iris data with ground truth labelling, Left: clustering produced by $k$-means, Right: clustering produced by meta-clustering. Quantitatively, error rate measure shows Meta-clustering produces significantly better quality clusters.}\n   \\label{fig:iris}\n\\end{figure*}\n\n\\subsection{Training with Real Data}\n\\label{sec:open-ml}\n\nFollowing \\cite{DBLP:conf/nips/Garg18}, we also train our model the on the repository of classfication datasets from openml \\citep{OpenML2013} database. By excluding labels, they can be viewed as clustering problems. For each experiment, we fetch all the datasets in openml repository that satisfied the desired feature dimensions and number of clusters (classes). We then randomly selected $10\\$ of the queried datasets for test and the rest for training. To emphasize the generalization power of our model, we do not tune the hyperparamters for each experiment and instead keep the architecture same for all the experiments. We randomly sample datapoints from each dataset to form meta-training and meta-test datasets. For each experiment, every meta-training or meta-test dataset has the same number of datapoints. To avoid imbalanced clusters dominating meta-training, we choose to sample each cluster uniformly (similar to \\citealp{Hsu2018UnsupervisedLV}). Like synthetic dataset generation, these datasets are sorted in the same way. \n\nTable~\\ref{tab:openml} shows the results when varying $k$ (the number of clusters), $N$ (the number of data points per meta dataset) and the range of feature dimensions. The feature dimension range is chosen such that the average number of datasets per feature dimension is high for effective training. We padded every dataset with zeros such that they all have the same dimension in each case. Results show that our Meta Clustering method typically has the lowest error rate.   out of all the clustering algorithms presented here for $k2$ and $k6$.\n\n\n\nNote that in some cases, there may not be enough datasets for training or the available datasets are not diverse enough or inherently hard to cluster. Unlike other deep clustering models, our model is only designed to learn to cluster so the performance can be limited by raw features. But as shown in the previous section, training on synthetic dataset can be helpful to clustering real data. Therefore, we augment the openml datasets with synthetic datasets for models that are under-trained by the available openml datasets, specifically, the experiments with $k3$ (28 datasets available) and $k4$ (20 datasets available). For $k3$, the newly trained model significantly out-performs other baselines. For $k4$, the error rate dropped getting closer to the best clustering algorithm in this experiment. Observe that it does not surpass every benchmark partially because the generalization ability of the model is limited by the training datasets; poorly chosen training datasets can be detrimental to meta clustering.\n\nWe also explore the case when the number of clusters is not fixed but rather chosen from a range. For methods like $k$-means, the choice of $k$ can be ambiguous. While there are approaches like Elbow methods to choose $k$, such heuristics are hard to apply across different datasets in the openml repository. So for clustering algorithm that requires $k$, we use the maximum number of possible clusters. This is also a fair comparison because the output dimension of our meta model is also fixed in the same way as described in Section~\\ref{sec:method}. Table~\\ref{tab:openml_multi_k} demonstrates that meta-clustering outperforms in this case as well (including the deep clustering DEC benchmark). {Notice that DEC (deep clustering benchmark) does not perform too well possibly due to limited data}.   too well because there isn't enough data to train auto-encoder which is trained for each meta dataset. This is a common problem for deep clustering algorithms. They require a large amount of data to train that may not be available for all the clustering datasets.}\n\n\n\\begin{table*}[h]\n   \\centering\n   \\setlength\\tabcolsep{2pt}\n   \\caption{Error rate on openml test datasets (100 samples). The second error rate of the Meta clustering column, if needed, comes from models trained with real datasets and synthetic datasets. $k$: number of clusters, $N$: number of data points per meta dataset, dims: the range of feature dimensions. \n   }. \n   \\begin{tabular}{ccccccc}\n   \\toprule\n   Method & $k$-means & Ker. $k$-means & Spec. Clust. & DBSCAN   & DEC & Meta Clust. \\\\\n   \\midrule\n   \\tabsplit{k   2, N   100 \\\\ dims: [1, 15]} & $\\textbf{0.38} \\pm \\textbf{0.09}$\t& $0.43 \\pm 0.07$ & $0.42 \\pm 0.10$ & $0.51 \\pm 0.05$ & $0.40 \\pm 0.09$ & \\tabsplit{$\\textbf{0.38} \\pm \\textbf{0.09}$ \\\\ \\NA} \\\\\n   \\midrule\n   \\tabsplit{k   3, N   100\\\\ dims: [1, 15]} & $0.11 \\pm 0.02$ & $0.13 \\pm 0.09$\t& $0.12 \\pm 0.05$\t& $0.29 \\pm 0.03$\t&$0.22 \\pm 0.14$ &   \\tabsplit{$0.34 \\pm 0.01$ \\\\ $\\textbf{0.02} \\pm \\textbf{0.01}$ }\\\\\n   \\midrule\n   \\tabsplit{k   4, N   500 \\\\ dims: [1, 20] } & $\\textbf{0.54} \\pm \\textbf{0.03}$\t& $0.62 \\pm 0.08$\t& $0.56 \\pm 0.05$\t& $0.74 \\pm 0.01$\t& $0.57 \\pm 0.08$& \\tabsplit{$0.63 \\pm 0.02$   \\\\ $0.58 \\pm 0.02$ }\\\\\n   \\midrule\n   \\tabsplit{k   6, N   500 \\\\ dims: [1, 40]} & $0.76 \\pm 0.01$\t& $0.79 \\pm 0.01$\t& $0.82 \\pm 0.00$\t& $0.83 \\pm 0.00$\t& $0.73 \\pm 0.09$ & \\tabsplit{$\\textbf{0.59} \\pm \\textbf{0.04}$\\\\ \\NA }\\\\\n   \\bottomrule\n   \\end{tabular}\n   \\label{tab:openml}\n\\end{table*}\n\n\\begin{table*}\n   \\centering\n   \\setlength\\tabcolsep{1.5pt}\n   \\caption{Error rate on openml test datasets with unknown $k$ (100 samples). \n   $k$: number of clusters, $N$: number of data points per meta dataset, dims: the range of feature dimensions. \n   }\n   \\begin{tabular}{cccccccc}\n   \\toprule\n   Method & $k$-means & Ker. $k$-means & Spec. Clust. & DBSCAN   & DEC & Meta Clust. \\\\\n   \\midrule\n   \\tabsplit{k   $\\{ 2,3,4 \\}$ N: 500 \\\\ dims: [1, 15]} & $0.60 \\pm 0.08$\t& $0.65 \\pm 0.08$ & $0.57 \\pm 0.11$ & $0.56 \\pm 0.09$ & $0.54 \\pm 0.09$ &$\\textbf{0.53} \\pm \\textbf{0.08}$\\\\\n   \\midrule\n   \\tabsplit{k   $\\{ 3,4,5 \\}$, N: 500\\\\ dims: [1, 15]} & $0.62 \\pm 0.05$ & $0.67 \\pm 0.09$\t& $0.59 \\pm 0.06$\t& $0.65 \\pm 0.10$& $0.60 \\pm 0.08$\t& $\\textbf{0.58} \\pm \\textbf{0.09}$\\\\\n   \\bottomrule\n   \\end{tabular}\n   \\label{tab:openml_multi_k}\n\\end{table*}\n",
  "title": "Meta-Learning to Cluster"
}
