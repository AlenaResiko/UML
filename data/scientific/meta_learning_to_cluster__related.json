{
  "authors": [
    "Yibo Jiang",
    "Nakul Verma"
  ],
  "date_published": "2019-10-30",
  "raw_tex": "\\textbf{Deep Learning for Clustering.} \\citet{DBLP:journals/corr/abs-1801-07648} provide an overview of all major frameworks that use deep learning for clustering tasks. Broadly, deep clustering consists of two parts: feature extraction phase and clustering phase. Usually feature extraction is done through an auto-encoder \\citep{hinton2006reducing}, which serves as a new representation for the subsequent clustering phase. \\citet{DBLP:conf/icml/HuMTMS17} propose an alternate approach using ``self-augmentation'', which encourages the new representation to map the input data close to its augmentation, hence acting as a regularizer.\n\nThough the extracted features can be used directly by standard clustering algorithms, deep learning models usually optimize further over specific clustering losses. \\citet{DBLP:conf/icml/YangFSH17}, for instance, propose to optimize over the $k$-means loss, thus encouraging learning $k$-means friendly feature representations.\n. $k$-means is effective if the new representation is $k$-means friendly meaning that the clusters are Gaussian shaped. \n\\citet{DBLP:conf/icml/XieGF16} on the other hand, use a loss based on student t-distribution and can accommodate for soft clusterings. to measure a soft clustering output.\n similarity band output corresponding probabilities (soft assignment), very much like t-SNE. \n\\citet{DBLP:conf/icml/XieGF16}, along with \\citet{DBLP:conf/icml/HuMTMS17}, further explore information-theoretic losses to achieve good clusterings.\n\nLike many deep architectures, deep clustering models require a large amount of data to train which may not be possible for many clustering problems. This pushes the need for a model that can work well in a data-limited scenario similar to one-shot or a few-shot learning settings in the supervised meta learning and this is where meta clustering can be effective.   \n\n\\textbf{Meta Learning.} Meta learning, often referred to as \\emph{learning to learn}, is closely related to one-shot or few-shot learning. It has shown promising results in supervised learning.\n   In the standard classification case, it can greatly benefit when training data is limited \\citep{DBLP:conf/icml/SantoroBBWL16}. In the reinforcement setting, it benefits by training more generalized agents rather than ones that specialize on a restricted domain \\citep{Wang2017LearningTR}. \n   \n\\TODO{if the following is ``not necessary'', then why discuss it? -- \nSome techniques include defining a distribution over the structure of the data and perform inference on top of it \\cite{DBLP:conf/cogsci/LakeSGT11} or its deep learning version ProtoNet \\cite{Snell2017PrototypicalNF}. But this kind of feature-related meta-learning is not necessary. }\n\nStandard approaches to learn a meta-learning model include defining a distribution over the structure of input data to perform inference \\citep{DBLP:conf/cogsci/LakeSGT11,Snell2017PrototypicalNF}, or to use a memory model such as long short-term memory model (LSTM, \\citealp{hochreiter1997long}) \\citep{DBLP:conf/icml/SantoroBBWL16,Wang2018PrefrontalCA} \nThere are several generic gradient-based learning methods developed for meta-learning, such as MAML \\citep{Finn2017ModelAgnosticMF} and Reptile \\citep{Nichol2018OnFM}. \nThese algorithms are specifically targeted for supervised and reinforcement meta-learning and are not effective in the unsupervised case.\n\n I DONT SEE A POINT FOR THE FOLLOWING SENTENCE\n NOT INTERESTED FOR THIS PAPER. BUT AT THE TIME, I THOUGHT IT IS INTERESTING TO INCLUDE IT IN THE REPORT\n\\cite{Wang2018PrefrontalCA} also suggest biological meaning for this type of algorithm where gradient descent can be viewed as dopamine and LSTM regarded as pre-frontal cortex.   \n\n\nMost of the current literature use meta learning to solve supervised learning and reinforcement learning \\cite{Mishra2017ASN}. \n\n To best of our knowledge there is no prior work on using deep meta-learning framework for unsupervised learning (either for clustering or for dimensionality reduction tasks). \nTo best of our knowledge, only a few works focus on using meta-learning framework for doing clustering. \n\\TODO{i have not researched into meta-learning for dimensionality reduction, so I can't say for sure. But, I mean, i don't think there is any work though based on some google search.}\nClosely related works by \\citet{DBLP:conf/semcco/FerrariC12} and \\citet{DBLP:journals/isci/FerrariC15} estimate which of the preexisting clustering losses works well for a new clustering task. Their approach is therefore limited to losses which the user has to provide. In contrast, we implicitly learn an appropriate loss for the new clustering task. \\citet{DBLP:conf/nips/Garg18} pushes the framework further, laying down the theoretical foundations for meta clustering. But like \\citet{DBLP:conf/semcco/FerrariC12} and \\citet{DBLP:journals/isci/FerrariC15}, \\citet{DBLP:conf/nips/Garg18} uses meta-attributes (like computing data covariance) rather than directly from the input. Moreover, it learns binary similarity functions without explicitly returning the clustering and compare   outputs with a simple majority rule. \nAnother interesting line of work by \\cite{Hsu2018UnsupervisedLV} uses unsupervised learning to improve upon the downstream supervised learning task.\nOur work on the other hand, specifically focuses on learning unsupervised clustering, and shows empirical success. \nNotice that both supervised and reinforcement meta-learning require some sort ``guidance\" from data in the form of labels (supervised) or rewards (reinforcement). This is fundamentally different from the unsupervised meta learning. By using a recurrent model and doing multiple passes through datapoints, we achieve ``self-guidance\" and consequently good performance.",
  "title": "Meta-Learning to Cluster"
}
