{
  "authors": [
    "Daniel Jiwoong Im",
    "Yibo Jiang",
    "Nakul Verma"
  ],
  "date_published": "2019-10-16",
  "raw_tex": "\\section{MODEL-AGNOSTIC META-LEARNING (MAML)}\n\\section{Model-agnostic Meta-learning (MAML)}\nModel-Agnostic Meta-Learning (MAML) was introduced by \\citet{Finn2017} with the aim \nIn a meta-learning setting, the goal is \nto \ntrain a model that can adapt to a \nlarge set of new tasks with only a few data points in a few learning iterations. \nGiven a meta-model $f$ parameterized by meta-parameters $\\theta$, one wants to find a gradient learning rule can make rapid progress on a new task.\nWe search for a meta-parameter $\\theta$ of meta-model $f$ such that the \ngradient learning rule can make rapid progress on a new task.\nThis can be formalized as follows:\nfor a task $\\mathcal{T}_i$ drawn from a distribution of tasks $p(\\mathcal{T})$, we require that\nsmall changes in parameters using gradient based parameter updates, that is (for any given learning rate $h$)\n\\begin{align}\n   \\theta^\\prime & \\theta - h \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(f(\\theta)),\n   \\label{eqn:basic_req}\n\\end{align}\nwould result in large improvement on loss function $\\mathcal{L}$ of a task $\\mathcal{T}_i$.\nThis requirement implies that meta-parameter $\\theta$ is an initialization that produces\na more transferable internal representation and achieves good prediction with only a few examples from a new task.   than other initial parameters.\n\n\nThe model-agnostic meta-learning (MAML) algorithm aims to find such a meta-parameter\nMAML finds such a meta-parameter by simultaneously minimizing loss functions associated with each task. \nIn meta-learning scenario, we consider a distribution over tasks $p(\\mathcal{T})$. \nThe MAML meta-objective is defined as \\citep{Finn2017}\n\\begin{align}\n\\hspace{-0.2in}\n   \\min_{\\theta} \\mathcal{L} (f(\\theta^\\prime)) &   \\nonumber\\\\\n   &\n   \\min_{\\theta} \\sum_{\\mathcal{T}_i \\sim p(\\mathcal{T})} \\mathcal{L}_{\\mathcal{T}_i}(f(\\theta - h \\nabla_\\theta \\mathcal{L} _{\\mathcal{T}_i}(f(\\theta)))),\n   \\label{eqn:maml_objective}\n\\end{align}\nwhere $\\theta'$ is as per Eq.\\ \\eqref{eqn:basic_req}, and the total loss $\\mathcal{L} (f(\\theta^\\prime))$ is simply the aggregate of the individual task specific losses $ \\sum_{\\mathcal{T}_i \\sim p(\\mathcal{T})} \\mathcal{L} _{\\mathcal{T}_i}(f(\\theta^\\prime))$.\nThus, the meta-parameter gets updated by taking a gradient descent step in the direction that minimizes loss for all the given tasks.\n\n\nAlgorithm~\\ref{algo:maml} provides an overview of the MAML training procedure.\nA batch of tasks is sampled from the task distribution $p(\\mathcal{T})$. The model parameters are then updated for each task (inner-updates). These updated parameters are then used to update the meta-parameter (outer-update).\n\nFor each task \n$\\mathcal{T}_i$, we update the parameters of model that are initialized using\nmeta-parameters. We evaluate the loss and compute the gradients with respect to meta-parameter \n$\\theta$ based on the updated parameters $\\theta^\\prime$ for each task. \n\nFor simplicity and ease of subsequent discussion, we will hide the model $f$ inside the loss $\\mathcal{L}$ and refer to it as $\\mathcal{L}(\\theta^\\prime)$ henceforth. That is, ${ \\mathcal{L}(\\theta^\\prime) : \\mathcal{L}_{\\mathcal{T}_i}(\\theta - h \\nabla_\\theta \\mathcal{L} _{\\mathcal{T}_i}(\\theta))}$.\nThe meta-optimization across tasks is performed via gradient descent method.\n\n\n\n\n\\begin{figure*}[t]\n   \\centering\n   \\begin{minipage}{0.493\\textwidth}\n   \\begin{algorithm}[H]\n   \\caption{MAML}\\label{algo:maml}\n   \\begin{algorithmic}[1]\n   \\Require{$\\alpha$ and $\\beta$ are learning rates}\n   \\Require{$p(\\mathcal{T})$ is distribution over tasks}\n   \\State Randomly initialize meta-parameter $\\theta\\theta_0$ \n   \\While {not done}:\n   \\State Sample batch of tasks $\\mathcal{T}_i \\sim p(\\mathcal{T})$ \n   \\For {all $\\mathcal{T}_i$} \n   \\State Evaluate $\\nabla_\\theta \\mathcal{L} _{\\mathcal{T}_i}$ with respect to $K$ data points.\n   \\State Update model parameter: \n   \\State $\\theta^{\\prime}   \\theta - \\alpha \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(f(\\theta))$\n   \\EndFor\n   \\State Update meta-parameter:\n   \\State $\\theta   \\theta - \\beta \\nabla_\\theta \\sum_{\\mathcal{T}_i\\in p(\\mathcal{T})} \\mathcal{L}_{\\mathcal{T}_i}(f(\\theta^\\prime))$\n   \\EndWhile\n   \\end{algorithmic}\n   \\end{algorithm}\n   \\end{minipage}\n   \\begin{minipage}{0.493\\textwidth}\n   \\begin{algorithm}[H]\n   \\caption{MAML-RK2}\\label{algo:gmaml2}\n   \\begin{algorithmic}[1]\n   \\Require{$\\alpha$ and $\\beta$ are learning rates}\n   \\Require{$p(\\mathcal{T})$ is distribution over tasks}\n   \\State Randomly initialize meta-parameter $\\theta\\theta_0$ \n   \\While {not done}:\n   \\State Sample batch of tasks $\\mathcal{T}_i \\sim p(\\mathcal{T})$ \n   \\For {all $\\mathcal{T}_i$} \n   \\State Evaluate $\\nabla_\\theta \\mathcal{L} _{\\mathcal{T}_i}$ with respect to $K$ data points.\n   \\State Update model parameter: \n   \\State $\\theta^{\\prime}   \\theta -   \\textcolor{red}{ h q_{21}} \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(f(\\theta))$\n   \\EndFor\n   \\State Update meta-parameter:\n   \\State   $\\theta   \\theta - \\textcolor{red}{h} \\sum_{\\mathcal{T}_i\\in p(\\mathcal{T})} \\textcolor{red}{ (a_1 \\nabla_{\\theta} \\mathcal{L}_{\\mathcal{T}_i}(f(\\theta)))} + \n   \\hspace{3in}\n   \\textcolor{red}{ a_2\\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(f(\\theta^\\prime)))}$\n   \\EndWhile\n   \\end{algorithmic}\n   \\end{algorithm}\n   \\end{minipage}   \n\\end{figure*}\n\n\n",
  "title": "Model-Agnostic Meta-Learning using Runge-Kutta Methods"
}
