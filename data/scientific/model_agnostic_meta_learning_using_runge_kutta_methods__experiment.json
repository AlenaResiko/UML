{
  "authors": [
    "Daniel Jiwoong Im",
    "Yibo Jiang",
    "Nakul Verma"
  ],
  "date_published": "2019-10-16",
  "raw_tex": "\\section{EXPERIMENTS}\n\\section{Experiments}\n\\label{sec:experiments}\n\n\n\n\n\n\nTo study the effectiveness of our extended Runge-Kutta MAML framework, we conducted detailed empirical studies of various explicit instantiations of second order MAML-RK methods (as detailed in \nin Section~\\ref{sec:maml-rk}) on various classification-, regression- and reinforcement- meta-learning benchmarks. \nTo assess whether applying RK methods to the MAML enhance the performance or \nnot, we tested MAML-RK on regression, classification, and reinforcement learning setup.\nThroughout the experiments, we compare the midpoint (i.e.\\ the original MAML optimization), Heun's, Ralston, ITB methods.\nThe data, models, and the optimizer for all our experiments is built upon the original MAML code\\footnote{MAML regression and classification code: \\texttt{http://github.com/cbfinn/maml}\nand MAML reinforcement learning code: \\texttt{http://github.com/cbfinn/maml\\_rl}.}.\n\n\n\nThe following standard setup is used in all our experiments. \nAll models are trained from the training task dataset and\nevaluated on the test task dataset. For each task, we have a support set of $K$ examples, which are used\nfor fast-adaption updates.   During the evaluation phase, the model is initialized with the learned meta-\nparameters from training phase, and is fine-tuned on the $K$ samples from the test tasks. The model architecture\nfor each experiment can be found in the Appendix.\n\n\n\n\\textbf{Regression} - Following the experiments in MAML \\citep{Finn2017}, we consider the sinusoid regression problem. For each task, the \n1-dimensional sinusoid wave of amplitude and phase are varied between $[0.1, 5.0]$ and $[0,\\pi]$, and\nthe goal is to regress on an unseen sinusoid wave. The datapoints are sampled from the range of $[-5.0,5.0]$ and \nwe used batch size of ten ($K10$) for every gradient update with a fixed step size of $0.01$. \nThe mean-square-error is used as a loss function. \nTable~\\ref{tab:regression_results} presents the regression performance.\nThe MAML-RK1 (the first-order method) corresponds to the pre-trained model on all training tasks, which is the\nbaseline method. Note that MAML-RK2 (midpoint) corresponds to original MAML method.\nWe observe that MAML-RK2 (Ralston) performs marginally better than the midpoint method for this simple task. \nNevertheless, the variance gap between the two overlaps.\nLastly, both methods are statistically far better than Heun's and ITB. \n\n\n\n\\textbf{Classification} - Next, we evaluate MAML-RK on classification tasks. It has been shown that MAML \\citep{Finn2017} achieved state-of-the-art performance when compared to prior meta-learning and few-shot learning algorithms \\citep{Koch2016, \nVinyals2016, Ravi2017} on few-shot Omniglot \\citep{Lake2011} and MiniImagenet \\citep{Ravi2017} image \n recognition tasks. Therefore, we only report MAML's results against other extended MAML-RK2 methods.\nThe standard setup for few-shot classification is that we consider $5$ and $20$ \nclasses ($N$-way) with 1-shot and 5-shot learning, and evaluate on new $5$ and $20$\nclasses. \n\n The Omniglot images were downsampled to $28\\times 28$ and were   augmented with up to 90\n degrees of rotation. The training task classes were randomly selected from 1200 out of 1623 \ncharacters and rest were used as test task classes.\nWe followed the same model architectures from previous studies \\citep{Vinyals2016, Finn2017}.\nFor MiniImage classification, the dataset consists of\n84$\\times$84 60,000 colored images. There are 100 different classes where each class\nconsists of 600 images. Out of the 100 classes, the training, validation, and test \nclasses were split as 64, 12, and 24 respectively. \n\nTable~\\ref{tab:omniglot_results} presents the performance on Omniglot dataset for\n5-way and 20-way classification for 1-shot and 5-shot learning.\nFor 5-way 1-shot and 20-way 1-shot learning, we observe that Ralston method performs \nthe best, and followed by Heun's and ITB. The midpoint method performs the worst. \nNote that the order of performance from Ralston, Heun, and ITB aligns with decrease in the \ncoefficient of $a_2$, which goes from $\\frac{2}{3}$, $\\frac{1}{2}$, and $\\frac{1}{3}$.\nHowever, even though the midpoint method has coefficent $a_21$, it's performance is\nworst than other three.\nWe suspect that this is because only the midpoint method has zero coefficient for $a_1$, \nwhich means that it cannot take the first-order gradient \ninformation $\\nabla \\mathcal{L}(\\theta)$ into account. Hence, setting the coefficient $a_1$ to be greater \nthan $0$ is important for achieving better results on this dataset.\nAgain for 5-way 5-shot learning, we observe that Ralston method performs the best and\nthe midpoint method performs the second best. \nNevertheless, MAML's mean plus the\nstandard deviation ($99.24+0.33$) does not surpass the mean performance of Ralston method, \nwhich is $99.61$. Figure~\\ref{fig:perm_iter} presents the performance of MAML against \nRalston method over the fast-adaption during the test time. \nFigure~\\ref{fig:perm_iter} (a-c) illustrates that Ralston outperforms MAML\nthroughout the training process. \nFor 20-way 5-shot learning, we found that all MAML-RK2 models perform\nmore or less the same, where the range of mean plus and minus the standard deviation\noverlaps. \nAlso, we did not see a big improvement on MiniImagenet dataset.\nHeun's method performed the best for the MiniImagenet dataset.\n\n\\begin{figure*}[t]\n   \\centering\n   \\begin{minipage}{0.244\\linewidth}\n   \\includegraphics[width\\linewidth]{maml_paths_viz.pdf} \n   \\subcaption{Midpoint (MAML)}\n   \\end{minipage}\n   \\begin{minipage}{0.244\\linewidth}\n   \\includegraphics[width\\linewidth]{heun_paths_viz.pdf} \n   \\subcaption{Heun's}   \n   \\end{minipage}\n   \\begin{minipage}{0.244\\linewidth}\n   \\includegraphics[width\\linewidth]{ralston_paths_viz.pdf} \n   \\subcaption{Ralston}\n   \\end{minipage}\n   \\begin{minipage}{0.244\\linewidth}\n   \\includegraphics[width\\linewidth]{itb_paths_viz.pdf} \n   \\subcaption{ITB}   \n   \\end{minipage}\n   \\vspace{-0.15cm}\n   \\caption{Illustration of fine-tuning using MAML-RK2 versus MAML on 2D Navigation task}\n   \\label{fig:point_traj}\n\\end{figure*}\n\n\\begin{wrapfigure}{r}{0.5\\textwidth}\n\\begin{figure}[htp]\n   \\centering\n   \\includegraphics[width\\linewidth]{point_results.pdf} \n   \\caption{The 2D navigation performance of MAML-RK2 over different number of gradient steps.}\n   \\label{fig:point_perf}\n   \\vspace{-0.4cm}\n\\end{figure}\n\\end{wrapfigure}\n\n\n\\textbf{Reinforcement Learning} - We evaluate MAML-RK2 on two types of reinforcement\nlearning environments, 2D navigation and locomotion. For training, REINFORCE was used\nfor policy   \\citep{Williams1992} and trust-region policy optimization (TRPO) was used for meta-optimization \\citep{Schulman2015}.\nFor 2D navigation, there are a set of tasks where a point agent must \nreach to different goal locations in 2D space. The state, the action, and the reward \ncorresponds to the 2D location, the motion velocity, and the distance to the goal \nrespectively. The simulation terminates when an agent navigates within 0.01 distance \nfrom the goal.   \n\nFigure~\\ref{fig:point_perf} presents the performance of MAML-RK2 for up to nine\ngradient updates with 40 samples. A model trained with random initialization\n(black triangle line) performs poorly even with nine gradient updates. \nThe red curve corresponds to the performance of model with oracle policy \nthat receives the goal position as input.\nWe observe that the midpoint method adapts the fastest upto three gradient \nupdates, however, it plateau after. Both Ralston and Heun's method reaches the \nperformance of oracle within five gradient updates. Eventually all methods except \nMAML reaches to the performance of oracle. \nRecall that $a_2$ corresponds to fast adaptation coefficient and $a_1$ corresponds to\ngood feature representation (because the higher the coefficient, the more it focuses on\n$\\nabla \\mathcal{L}(\\theta^\\prime)$ and less on $\\nabla \\mathcal{L}(\\theta)$). \nInterestingly, according to the plots in Figure \\ref{fig:point_perf} the learning speed is ordered as follows: the midpoint, Ralston,\nHeun's, and ITB methods.   This ordering corresponds to the ordering of coefficient of $a_2$,\nwhich is $1$, $\\frac{2}{3}$, $\\frac{1}{2}$, and $\\frac{1}{3}$ respectively.\nThe midpoint method suffers from poor performance the most. We suspect that\nthis is because it only emphasizes $\\nabla \\mathcal{L}(\\theta^\\prime)$ \\change{(fast-adaptation)} part and\nignores $\\nabla \\mathcal{L}(\\theta)$ \\change{(shared-representation)} part. \nRalston method seems to achieve the right balance between the two terms as the performance reaches to \nthe oracle (red level) the fastest.\n\nLastly, Figure~\\ref{fig:point_traj} illustrates the actual trajectory of learning towards\nthe final location. The results shows that the midpoint method takes long time to find the goal location and jitters a lot (showing suboptimal temporal dynamics). On the other hand, ITB finds the goal location\nwithin very few steps. Although Ralston and Heun's are in between the midpoint and ITB,\nboth methods still take much fewer steps to converge to the goal. \nThis clearly demonstrates the role between optimizing under \n $\\nabla \\mathcal{L}(\\theta^\\prime)$ versus $\\nabla \\mathcal{L}(\\theta)$.\n\n",
  "title": "Model-Agnostic Meta-Learning using Runge-Kutta Methods"
}
