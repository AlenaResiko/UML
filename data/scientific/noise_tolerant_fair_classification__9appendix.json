{
  "authors": [
    "Alexandre Louis Lamy",
    "Ziyuan Zhong",
    "Aditya Krishna Menon",
    "Nakul Verma"
  ],
  "date_published": "2019-01-30",
  "raw_tex": "auto-ignore\n\\begin{appendices}\n\n\n\n\n\\section{Proofs of results in the main body}\n\\label{sec:proof of main theorem}\n\n\\subsection{Proof of Lemma~\\ref{lemma:mcrelation}}\n\\begin{proof} Proof of Lemma~\\ref{lemma:mcrelation}]\n   Suppose that we have noise as given by Equation \\eqref{equation:mcnoise1}. We denote by $A$ the random variable\n   denoting the value of the true sensitive attribute and by $A_{\\mathrm{corr}}$ the random variable denoting the value \n   of the corrupted sensitive attribute.\n\n   Then, for any measurable subset of instances $U$,\n   \n   \n   \\ifpaper\n   \\begin{align*}\n   &\\mathbb{P}[X \\in U \\mid Y   1 , A_{\\mathrm{corr}}   1]\\\\\n   & \\frac{ \\mathbb{P}[X \\in U, Y1 \\mid A_{\\mathrm{corr}}   1] }{\\mathbb{P}[Y1 \\mid A_{\\mathrm{corr}}   1]} \\\\\n   & \\frac{ \\mathbb{P}[X \\in U, Y1 \\mid A_{\\mathrm{corr}}   1] }{(1-\\alpha)\\mathbb{P}[Y1 \\mid A   1] + \\alpha \\mathbb{P}[Y1 \\mid A0]} \\\\\n   & \\frac{ (1-\\alpha)\\mathbb{P}[X \\in U, Y1 \\mid A   1] }{(1-\\alpha)\\mathbb{P}[Y1 \\mid A   1] + \\alpha \\mathbb{P}[Y1 \\mid A0]} \\\\\n   &\\phantom{} + \\frac{\\alpha\\mathbb{P}[X \\in U, Y1 \\mid A   0] }{(1-\\alpha)\\mathbb{P}[Y1 \\mid A   1] + \\alpha \\mathbb{P}[Y1 \\mid A0]} \\\\\n   & \\frac{ (1-\\alpha)\\mathbb{P}[Y1 \\mid A1]\\mathbb{P}[X \\in U \\mid Y1, A   1]}{(1-\\alpha)\\mathbb{P}[Y1 \\mid A   1] + \\alpha \\mathbb{P}[Y1 \\mid A0]} \\\\\n   &\\phantom{} + \\frac{\\alpha\\mathbb{P}[Y1 \\mid A   0]\\mathbb{P}[X \\in U \\mid Y1, A   0] }{(1-\\alpha)\\mathbb{P}[Y1 \\mid A   1] + \\alpha \\mathbb{P}[Y1 \\mid A0]} \\\\\n   & (1-\\alpha')\\mathbb{P}[X \\in U \\mid Y1, A   1] \\\\\n   &\\phantom{} + \\alpha' \\mathbb{P}[X \\in U \\mid Y1, A   0],\n   \\end{align*}\n   \\fi\n   \n   \\ifarxiv\n   \\begin{align*}\n   &\\mathbb{P}[X \\in U \\mid Y   1 , A_{\\mathrm{corr}}   1]\\\\\n   & \\frac{ \\mathbb{P}[X \\in U, Y1 \\mid A_{\\mathrm{corr}}   1] }{\\mathbb{P}[Y1 \\mid A_{\\mathrm{corr}}   1]} \\\\\n   & \\frac{ \\mathbb{P}[X \\in U, Y1 \\mid A_{\\mathrm{corr}}   1] }{(1-\\alpha)\\mathbb{P}[Y1 \\mid A   1] + \\alpha \\mathbb{P}[Y1 \\mid A0]} \\\\\n   & \\frac{ (1-\\alpha)\\mathbb{P}[X \\in U, Y1 \\mid A   1] }{(1-\\alpha)\\mathbb{P}[Y1 \\mid A   1] + \\alpha \\mathbb{P}[Y1 \\mid A0]} + \\frac{\\alpha\\mathbb{P}[X \\in U, Y1 \\mid A   0] }{(1-\\alpha)\\mathbb{P}[Y1 \\mid A   1] + \\alpha \\mathbb{P}[Y1 \\mid A0]} \\\\\n   & \\frac{ (1-\\alpha)\\mathbb{P}[Y1 \\mid A1]\\mathbb{P}[X \\in U \\mid Y1, A   1]}{(1-\\alpha)\\mathbb{P}[Y1 \\mid A   1] + \\alpha \\mathbb{P}[Y1 \\mid A0]} + \\frac{\\alpha\\mathbb{P}[Y1 \\mid A   0]\\mathbb{P}[X \\in U \\mid Y1, A   0] }{(1-\\alpha)\\mathbb{P}[Y1 \\mid A   1] + \\alpha \\mathbb{P}[Y1 \\mid A0]} \\\\\n   & (1-\\alpha')\\mathbb{P}[X \\in U \\mid Y1, A   1] + \\alpha' \\mathbb{P}[X \\in U \\mid Y1, A   0],\n   \\end{align*}\n   \\fi\n   \n   \n   where in the last equality we set \n   \\begin{equation*}\n   \\resizebox{\n   \\ifdim\\width>\\linewidth\n   \\linewidth\n   \\else\n   \\width\n   \\fi\n   }{!}{$\\displaystyle\n   \\alpha' : \\frac{\\alpha\\mathbb{P}[Y1 \\mid A   0] }{(1-\\alpha)\\mathbb{P}[Y1 \\mid A   1] + \\alpha \\mathbb{P}[Y1 \\mid A0]}.$\n   }\n   \\end{equation*}\n   Note that the last equality is equivalent to the first equality of Equation \\eqref{equation:mcnoise2}\n   with $\\alpha'$ as in the lemma.\n   \n   The proof for $\\beta'$ is exactly the same and simply expands $\\mathbb{P}[X \\in U \\mid Y   1 , A_{\\mathrm{corr}}   0]$\n   instead of $\\mathbb{P}[X \\in U \\mid Y   1 , A_{\\mathrm{corr}}   1]$.\n\\end{proof}\n\n\\subsection{Proof of Theorem~\\ref{thm: sensitive noise reduction}}\n\\begin{proof}[Proof of Theorem~\\ref{thm: sensitive noise reduction}]\n   For the DP-like constraints simply note that by definition of $D_{\\mathrm{corr}}$ we have that\n   $$\\Lf_{D_{0,\\cdot, \\mathrm{corr}}}(f)   (1-\\beta) \\cdot \\Lf_{D_{0,\\cdot}}(f) + \\beta \\cdot \\Lf_{D_{1,\\cdot}}(f)$$\n   and similarly,\n   $$\\Lf_{D_{1,\\cdot, \\mathrm{corr}}}(f)   (1-\\alpha) \\cdot \\Lf_{D_{1,\\cdot}}(f) + \\alpha \\cdot \\Lf_{D_{0,\\cdot}}(f)$$\n   Thus we have that\n   \\ifpaper\n   \\begin{align*}\n   \\Lf_{D_{0,\\cdot, \\mathrm{corr}}}(f)-\\Lf_{D_{1,\\cdot, \\mathrm{corr}}}(f)   &\\, (1-\\alpha-\\beta) \\cdot \\\\\n   &(\\Lf_{D_{0,\\cdot}}(f) - \\Lf_{D_{1,\\cdot}}(f)),\n   \\end{align*}\n   \\fi\n   \n   \\ifarxiv\n   \\begin{align*}\n   \\Lf_{D_{0,\\cdot, \\mathrm{corr}}}(f)-\\Lf_{D_{1,\\cdot, \\mathrm{corr}}}(f)   &\\, (1-\\alpha-\\beta) \\cdot (\\Lf_{D_{0,\\cdot}}(f) - \\Lf_{D_{1,\\cdot}}(f)),\n   \\end{align*}\n   \\fi\n   which immediately implies the desired result.\n   \n   The result for the EO constraint is obtained in the exact same way by simply replacing \n   $D_{a, \\cdot}$ with \n   $D_{a, 1}$, $D_{a, \\cdot, \\text{corr}}$ with $D_{a, 1, \\text{corr}}$, and $\\alpha$ and $\\beta$ with\n   $\\alpha'$ and $\\beta'$.\n\\end{proof}\n\n\\subsection{Proof of Lemma~\\ref{thm: randomized response for differential privacy}}\n\\begin{proof}[Proof of Lemma~\\ref{thm: randomized response for differential privacy}]\nBasic definitions in Differential Privacy are provided in Appendix~\\ref{sec:diff-privacy}. Consider an instance $\\{x_i,y_i,a_i\\}$ with only $x_i$ disclosed by an attacker. Assume the sensitive attribute $a_i$ is queried. Denote $\\hat{a}_i$ to be the sensitive attribute of the instance after adding noise i.e. being flipped with probability $\\rho$. The attacker is interested in knowing if $a_i0$ or $a_i1$ by querying $\\hat{a}_i$.\n\nSince\n\\begin{align*}\n   \\frac{\\mathbb{P} [\\hat{a}_i1 | a_i1]}{\\mathbb{P} [\\hat{a}_i1 | a_i0]}\\frac{\\mathbb{P} [\\hat{a}_i0 | a_i0]}{\\mathbb{P} [\\hat{a}_i0 | a_i1]}\n\\end{align*}\nwe can reason in a similar way for $\\hat{a}_i0$. Thus, let us focus on the case where $\\hat{a}_i1$.   Let us consider two neighbor instances $\\{x_i,y_i,0\\}$ and $\\{x_i,y_i,1\\}$.\nEssentially, we want to upper-bound the ratio \n\\[\n\\frac{\\mathbb{P} [\\hat{a}1|a_i1]}{\\mathbb{P} [\\hat{a}1|a_i0]} : \\frac{1-\\rho}{\\rho}\n\\]\nby $\\exp (\\epsilon)$, and lower-bound the ratio by $\\exp (-\\epsilon)$.\nThe lower bound is always true since $\\rho<0.5$. For the upper-bound, We have:\n\\begin{align*}\n   \\frac{1-\\rho}{\\rho} \\leq \\exp{(\\epsilon)} \\iff \\rho \\geq \\frac{1}{\\exp (\\epsilon)+1}.\n\\end{align*}\n\\end{proof}\n\n\n\\clearpage\n\n\n\\section{Background on Differential Privacy}\n\\label{sec:diff-privacy}\n\nThe following definitions are from Appendix~\\citet{Dwork06}. They are used for the proof of Lemma~\\ref{thm: randomized response for differential privacy} in~\\ref{sec:proof of main theorem}.\n\n\\textbf{Probability simplex}: Given a discrete set $B$, the probability simplex over $B$, denoted $\\Delta (B)$ is:\n\\[\n\\Delta (B)   \\{ x \\in \\mathbb{R}^{\\vert B \\vert }: \\forall i, x_i \\geq 0, \\text{ and } \\sum_{i1}^{\\vert B \\vert} x_i   1\\}.\n\\]\n\\textbf{Randomized Algorithms}: A randomized algorithm $\\mathcal{M}$ with domain $A$ and range $B$ is an algorithm associated with a total map $M:A\\rightarrow \\Delta (B)$. On input $a \\in A$, the algorithm $\\mathcal{M}$ outputs $\\mathcal{M}(a)b$ with probability $(M(a))_b$ for each $b \\in B$. The probability space is over the coin flips of the algorithm $\\mathcal{M}$.\n\nFor simplicity we will avoid implementation details and we will consider databases as histograms. Given a universe $\\mathcal{X}$ an histogram over $\\mathcal{X}$ is an object in $\\mathbb{N}^{\\vert \\mathcal{X} \\vert}$. We can bake in the presence or absence of an individual notion in a definition of distance between databases.\\\\\n\n\\textbf{Distance Between Databases}: The $l_1$ norm $\\| x \\|_1$ of a database $x \\in \\mathbb{N}^{\\vert \\mathcal{X} \\vert}$ is defined as:\n\\[\n\\| x \\|_1   \\sum_{i1}^{\\vert \\mathcal{X} \\vert} x_i.\n\\]\nThe $l_1$ distance between two databases $x$ and $y$ is defined as   $\\| x - y \\|_1$.\\\\\n\n\\textbf{Differential Privacy}: A randomized algorithm $\\mathcal{M}$ with domain $\\mathbb{N}^{\\vert \\mathcal{X} \\vert}$ is $(\\epsilon, \\delta)$-differentially private if for all $S \\subseteq$ Range$(\\mathcal{M})$ and for all $x,y\\in \\mathbb{N}^{\\mathcal{X}}$ such that $\\| x-y \\|_1 \\leq 1$:\n\\[\n\\mathbb{P} [\\mathcal{M}(x) \\in S] \\leq \\exp(\\epsilon) \\cdot \\mathbb{P} [\\mathcal{M}(y)\\in S]+\\delta,\n\\]\nwhere the probability space is over the coin flips of the mechanism $\\mathcal{M}$.\n\n\n\\clearpage\n\n\n\n\\section{Relationship between mean-difference score and the constraint used in \\citet{reduction}}\n\\label{appendix:agarwal_constraint}\n\n\\citet{reduction} adopts slightly different fairness constraints than ours. Using our notation and letting $\\signf(X)   \\sign(f(X))$, instead of bounding   $\\Lambda^{\\mathrm{DP}}_D( f )$ by $\\tau$, they bound \n$$\\max_{a\\in\\{0,1\\}} \\abs{\\mathbb{E}_{D_{a,\\cdot}}[\\signf(X)] - \\mathbb{E}_D[\\signf(X)]}$$ and $$\\max_{a\\in\\{0,1\\}} \\abs{\\mathbb{E}_{D_{a,1}}[\\signf(X)] - \\mathbb{E}_{D_{\\cdot, 1}}[\\signf(X)]}$$ for DP and EO respectively   by $\\tau$.\nThe two have the following relationship.\n\\begin{theorem}\nUnder the setting of fair binary classification with a single binary sensitive attribute and using $\\ellf(s, y)   \\1[\\sign(s)]$ we have that\n\\[\n\\max_{a\\in\\{0,1\\}} \\abs{\\mathbb{E}_{D_{a, \\cdot}}[\\signf(X)] - \\mathbb{E}_D[\\signf(X)]}   \\max_{a\\in\\{0,1\\}} ( \\mathbb{P}[A   0], \\mathbb{P}[A   1] ) \\Lambda^{\\mathrm{DP}}_D( f )\n\\]\nand\n\\[\n\\max_{a\\in\\{0,1\\}} \\abs{\\mathbb{E}_{D_{a, 1}}[\\signf(X)] - \\mathbb{E}_{D_{\\cdot, 1}}[\\signf(X)]}   \\max_{a\\in\\{0,1\\}} ( \\mathbb{P}[A   0 \\mid Y   1], \\mathbb{P}[A   1 \\mid Y   1] ) \\Lambda^{\\mathrm{EO}}_D( f )\n\\]\n\\end{theorem}\n\\begin{proof}\nFor the DP case,\n\\begin{align*}\n   &\\abs{\\mathbb{E}_{D_{1,\\cdot}}[\\signf(X)] - \\mathbb{E}_D[\\signf(X)]}\n   \\\\& \\abs{\\mathbb{E}_{D_{1,\\cdot}}[\\signf(X)] - (\\mathbb{P}[A1]\\mathbb{E}_{D_{1,\\cdot}}[\\signf(X)]+\\mathbb{P}[A0]\\mathbb{E}_{D_{0,\\cdot}}[\\signf(X)])}\\\\\n   & \\abs{(1-\\mathbb{P}[A1])\\mathbb{E}_{D_{1,\\cdot}}[\\signf(X)]-\\mathbb{P}[A   0]\\mathbb{E}_{D_{0,\\cdot}}[\\signf(X)]}\\\\\n   & \\abs{\\mathbb{P}[A0]\\mathbb{E}_{D_{1,\\cdot}}[\\signf(X)]-\\mathbb{P}[A0]\\mathbb{E}_{D_{0,\\cdot}}[\\signf(X)]}\\\\\n   & \\mathbb{P}[A0]\\abs{(\\mathbb{E}_{D_{1,\\cdot}}[\\signf(X)]-\\mathbb{E}_{D_{0,\\cdot}}[\\signf(X)])}\\\\\n   & \\mathbb{P}[A0]\\abs{ \\Lf_{D_{0, \\cdot}}(f) - \\Lf_{D_{1, \\cdot}}(f) }\\\\\n   & \\mathbb{P}[A0]\\Lambda^{\\mathrm{DP}}_D( f )\n\\end{align*}\n\nand similarly\n\\[\n\\abs{\\mathbb{E}_{D_{0,\\cdot}}[\\signf(X)]-\\mathbb{E}_D[\\signf(X)]}   \\mathbb{P}[A1]\\Lambda^{\\mathrm{DP}}_D( f )\n\\]\nso the theorem holds.\n\nThe result for the EO case is proved in exactly the same way by simply replacing $\\mathbb{P}[A0], \\mathbb{P}[A1],$ $D_{a,\\cdot}$ and $D$ with $\\mathbb{P}[A0 \\mid Y1], \\mathbb{P}[A1 \\mid Y1],$ $D_{a,1}$ and $D_{\\cdot, 1}$ respectively.\n\n\\end{proof}\n\nWe then have the following as an immediate corollary.\n\\begin{corollary}\nAssuming that we have noise as described above by Equation \\eqref{equation:mcnoise1} and that we take $\\ellf(s, y)   \\1[\\sign(s)]$ then we have that if $\\max_{a\\in\\{0,1\\}} ( \\mathbb{P}_D[A   0], \\mathbb{P}_D[A   1] )   \\max_{a\\in\\{0,1\\}} ( \\mathbb{P}_{D_\\mathrm{corr}}[A   0], \\mathbb{P}_{D_\\mathrm{corr}}[A   1] )$ then:\n\\[\n\\max_{a\\in\\{0,\\cdot\\}} \\abs{\\mathbb{E}_{D_{a,\\cdot}}[\\signf(X)] - \\mathbb{E}_D[\\signf(X)]} < \\tau \\iff \\max_{a\\in\\{0,1\\}} \\abs{\\mathbb{E}_{D_{a,\\cdot,\\textrm{corr}}}[\\signf(X)] - \\mathbb{E}_{D_{\\textrm{corr}}}[\\signf(X)]} < \\tau \\cdot (1-\\alpha-\\beta).\n\\]\nAnd if $\\max_{a\\in\\{0,1\\}} ( \\mathbb{P}_{D_{\\cdot, 1}}[A   0], \\mathbb{P}_{D_{\\cdot, 1}}[A   1] )   \\max_{a\\in\\{0,1\\}} ( \\mathbb{P}_{D_{\\cdot, 1, \\mathrm{corr}}}[A   0], \\mathbb{P}_{D_{\\cdot, 1, \\mathrm{corr}}}[A   1] )$ then: \n\\[\n\\max_{a\\in\\{0,1\\}} \\abs{\\mathbb{E}_{D_{a,1}}[\\signf(X)] - \\mathbb{E}_{D_{\\cdot,1}}[\\signf(X)]} < \\tau \\iff \\max_{a\\in\\{0,1\\}} \\abs{\\mathbb{E}_{D_{a,1,\\textrm{corr}}}[\\signf(X)] - \\mathbb{E}_{D_{\\cdot,1,\\textrm{corr}}}[\\signf(X)]} < \\tau \\cdot (1-\\alpha'-\\beta').\n\\]\n\\end{corollary}\nEven if the noise does not satisfy these new assumptions, we can still bound the constraint. Note that both $\\max_{a\\in\\{0,1\\}} ( \\mathbb{P}[A   0], \\mathbb{P}[A   1] )$ and $\\max_{a\\in\\{0,1\\}} ( \\mathbb{P}[A   0 \\mid Y   1], \\mathbb{P}[A   1 \\mid Y   1] )$ have values between $0.5$ and $1$. Thus,\n\\[\n\\frac{1}{2} \\Lambda^{\\mathrm{DP}}_D( f ) \\leq \\max_{a\\in \\{0,1\\}}\\abs{\\mathbb{E}_{D_{a,\\cdot}}[\\signf(X)]-\\mathbb{E}_D[\\signf(X)]} \\leq \\Lambda^{\\mathrm{DP}}_D( f )\n\\]\n\\[\n\\frac{1}{2} \\Lambda^{\\mathrm{EO}}_D( f ) \\leq \\max_{a\\in \\{0,1\\}}\\abs{\\mathbb{E}_{D_{a,1}}[\\signf(X)]-\\mathbb{E}_{D_{\\cdot,1}}[\\signf(X)]} \\leq \\Lambda^{\\mathrm{EO}}_D( f ),\n\\] and therefore the following corollary holds:\n\\begin{corollary}\nAssuming that we have noise as described above by Equation \\eqref{equation:mcnoise1} and that we take $\\ellf(s, y)   \\1[\\sign(s)]$ then we have that:\n\\[\n \\max_{a\\in\\{0,1\\}} \\abs{\\mathbb{E}_{D_{a,\\cdot,\\textrm{corr}}}[\\signf(X)] - \\mathbb{E}_{D_{\\textrm{corr}}}[\\signf(X)]} < \\frac{1}{2} \\tau \\cdot (1-\\alpha-\\beta)\n \\Rightarrow\n \\max_{a\\in\\{0,1\\}} \\abs{\\mathbb{E}_{D_{a,\\cdot}}[\\signf(X)] - \\mathbb{E}_D[\\signf(X)]} < \\tau\n\\]\nand,\n\\[\n \\max_{a\\in\\{0,1\\}} \\abs{\\mathbb{E}_{D_{a,1,\\textrm{corr}}}[\\signf(X)] - \\mathbb{E}_{D_{\\cdot,1,\\textrm{corr}}}[\\signf(X)]} < \\frac{1}{2} \\tau \\cdot (1-\\alpha'-\\beta')\n \\Rightarrow\n \\max_{a\\in\\{0,1\\}} \\abs{\\mathbb{E}_{D_{a,1}}[\\signf(X)] - \\mathbb{E}_{D_{\\cdot,1}}[\\signf(X)]} < \\tau.\n\\]\n\\end{corollary}\n\nIn addition to giving a simple way to use the classifier of \\citet{reduction} without any modification, these results seem to indicate that with small modifications our scaling method can apply to an even wider range of fair classifiers than formally shown.\n\n\\clearpage\n\n\n\\section{More results for the privacy case study}\n\\label{appendix:privacy}\nIn this section we give some additional results for the privacy case study. \n\n\\aditya{Placeholder, need to expand.}\n{Figure~\\ref{fig:DP_compas_full} shows additional results on {\\tt COMPASS} for different noise levels $\\rho^+   \\rho^- \\in \\{0.15, 0.3\\}$.}\n\n\\begin{figure*}[!h]\n   \\centering\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{disp_test_compas,0.15,0.15,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{disp_test_compas,0.3,0.3,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{error_test_compas,0.15,0.15,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{error_test_compas,0.3,0.3,1.0,DP,Agarwal,3,False}.pdf}\n\n\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{disp_train_compas,0.15,0.15,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{disp_train_compas,0.3,0.3,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{error_train_compas,0.15,0.15,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{error_train_compas,0.3,0.3,1.0,DP,Agarwal,3,False}.pdf}\n   \\caption{Relationship between input $\\tau$ and fairness violation/error on the {\\tt COMPAS} dataset using DP constraint (testing curves). The black dotted line \n   {gray dashed line} represents the ideal fairness violation.}\n   \\label{fig:DP_compas_full}\n\\end{figure*}\n\nFigure~\\ref{fig:EO_compas} shows the results under the EO constraint for the {\\tt COMPAS} dataset. That is, the dataset and setting is the same as described in section \\ref{casestudy: privacy} but with the EO constraint instead of the DP constraint. We see that the trends are the same.\n\n\\begin{figure*}[h]\n   \\centering\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{disp_test_compas,0.15,0.15,1.0,EO,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{disp_test_compas,0.3,0.3,1.0,EO,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{error_test_compas,0.15,0.15,1.0,EO,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{error_test_compas,0.3,0.3,1.0,EO,Agarwal,3,False}.pdf}\n   \n   \\includegraphics[width0.24\\textwidth]{img_privacy/{disp_train_compas,0.15,0.15,1.0,EO,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{disp_train_compas,0.3,0.3,1.0,EO,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{error_train_compas,0.15,0.15,1.0,EO,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy/{error_train_compas,0.3,0.3,1.0,EO,Agarwal,3,False}.pdf}\n   \n   \\caption{(EO)(testing and training) Relationship between input $\\tau$ and fairness violation/error on the {\\tt COMPAS} dataset.}\n   \\label{fig:EO_compas}\n\\end{figure*}\n\nFigures \\ref{fig:bank_training} and Figure \\ref{fig:bank_testing} show results on the {\\tt bank} dataset~\\citep{Bank} with the DP and EO constraints respectively. This dataset is a subset of the original Bank Marketing dataset from the UCI repository~\\citep{UCI}. The task is to predict if a client subscribes a term deposit. The sensitive attribute is if a person is middle aged(i.e. has an age between 25 and 60). The data comprises 11162 examples and 17 features. Again we note that the trends are the same.\n\n\n\n\n\n\\begin{figure*}[h]\n   \\centering\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{disp_test_bank,0.2,0.2,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{disp_test_bank,0.4,0.4,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{error_test_bank,0.2,0.2,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{error_test_bank,0.4,0.4,1.0,DP,Agarwal,3,False}.pdf}\n   \n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{disp_train_bank,0.2,0.2,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{disp_train_bank,0.4,0.4,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{error_train_bank,0.2,0.2,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{error_train_bank,0.4,0.4,1.0,DP,Agarwal,3,False}.pdf}\n   \n   \\caption{(DP)(testing and training) Relationship between input $\\tau$ and fairness violation/error on the {\\tt bank} dataset.}\n   \\label{fig:bank_training}\n\\end{figure*}\n\n\n\n\\begin{figure*}[h]\n   \\centering\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{disp_train_bank,0.2,0.2,1.0,EO,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{disp_train_bank,0.4,0.4,1.0,EO,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{error_train_bank,0.2,0.2,1.0,EO,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{error_train_bank,0.4,0.4,1.0,EO,Agarwal,3,False}.pdf}\n   \n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{disp_test_bank,0.2,0.2,1.0,EO,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{disp_test_bank,0.4,0.4,1.0,EO,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{error_test_bank,0.2,0.2,1.0,EO,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_privacy_bank/{error_test_bank,0.4,0.4,1.0,EO,Agarwal,3,False}.pdf}\n   \n   \\caption{(EO)(testing and training) Relationship between input $\\tau$ and fairness violation/error on the {\\tt bank} dataset.}\n   \\label{fig:bank_testing}\n\\end{figure*}\n\n\n\\clearpage\n\n\n\\section{More results for the PU case study}\n\\label{appendix:pu}\nIn this section we give some additional results for the PU case study. \n\n\\aditya{Placeholder, need to expand.}\n{Figure~\\ref{fig:law_full} shows additional results on {\\tt law school} for different noise levels $\\rho^+   \\rho^- \\in \\{0.2, 0.4\\}$.} {Figure~\\ref{fig:law_est_err_diff_tau} shows additional results under noise rate estimation on {\\tt law school} for different upper bound of fairness violation: $\\tau \\in \\{0.1, 0.3\\}$.}\n\n\\begin{figure*}[!h]\n   \\centering\n   \\includegraphics[width0.24\\textwidth]{img_pu_law/{disp_test_law,0.0,0.2,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_pu_law/{disp_test_law,0.0,0.4,1.0,DP,Agarwal,3,False}.pdf}   \n   \\includegraphics[width0.24\\textwidth]{img_pu_law/{error_test_law,0.0,0.2,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_pu_law/{error_test_law,0.0,0.4,1.0,DP,Agarwal,3,False}.pdf}\n   \n   \\includegraphics[width0.24\\textwidth]{img_pu_law/{disp_train_law,0.0,0.2,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_pu_law/{disp_train_law,0.0,0.4,1.0,DP,Agarwal,3,False}.pdf}   \n   \\includegraphics[width0.24\\textwidth]{img_pu_law/{error_train_law,0.0,0.2,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_pu_law/{error_train_law,0.0,0.4,1.0,DP,Agarwal,3,False}.pdf}\n\n   \\caption{Relationship between input $\\tau$ and fairness violation/error on the {\\tt law school} dataset using DP constraint (testing curves). The black dotted \n   {gray dashed line} represents the ideal fairness violation. Note that in some of the graphs, the red line and the orange line perfectly overlap with each other.}\n   \\label{fig:law_full}\n\\end{figure*}\n\n\n\nauto-ignore\n\\begin{figure*}[!t]\n   \\centering\n   \\includegraphics[width0.24\\textwidth]{{img_pu_law_noise_est/disp_test_law,tau0.1,0.0,0.2,1,DP,Agarwal,3,False,test_rho_est_err}.pdf}\n   \\includegraphics[width0.24\\textwidth]{{img_pu_law_noise_est/disp_test_law,tau0.3,0.0,0.2,1,DP,Agarwal,3,False,test_rho_est_err}.pdf}   \n   \\includegraphics[width0.24\\textwidth]{{img_pu_law_noise_est/error_test_law,tau0.1,0.0,0.2,1,DP,Agarwal,3,False,test_rho_est_err}.pdf}\n   \\includegraphics[width0.24\\textwidth]{{img_pu_law_noise_est/error_test_law,tau0.3,0.0,0.2,1,DP,Agarwal,3,False,test_rho_est_err}.pdf}\n   \\caption{Relationship between the estimated noise level $\\hat{\\rho}^-$ and fairness violation/error on the {\\tt law school} dataset using DP constraint (testing curves) at $\\tau \\in \\{0.1, 0.3\\}$, with $\\hat{\\rho}^+   0$.}\n   \\label{fig:law_est_err_diff_tau}\n\\end{figure*}\n\nFigure \\ref{fig:DP_german} and Figure \\ref{fig:german_est_err} show the results under PU noise on the {\\tt german} dataset, which is another dataset from the UCI repository ~\\citep{UCI}. The task is to predict if one has good credit and the sensitive attribute is whether a person is foreign. The data comprises 1000 examples and 20 features. The trends are similar to those for the {\\tt law school} dataset.\n\n\n\n\n\\begin{figure*}[h]\n   \\centering\n   \\includegraphics[width0.24\\textwidth]{img_pu_german/{disp_test_german,0.2,0.0,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_pu_german/{disp_test_german,0.4,0.0,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_pu_german/{error_test_german,0.2,0.0,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_pu_german/{error_test_german,0.4,0.0,1.0,DP,Agarwal,3,False}.pdf}\n   \n   \\includegraphics[width0.24\\textwidth]{img_pu_german/{disp_train_german,0.2,0.0,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_pu_german/{disp_train_german,0.4,0.0,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_pu_german/{error_train_german,0.2,0.0,1.0,DP,Agarwal,3,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{img_pu_german/{error_train_german,0.4,0.0,1.0,DP,Agarwal,3,False}.pdf}\n   \n   \\caption{(DP)(training and testing) Relationship between input $\\tau$ and fairness violation/error on the {\\tt german} dataset.}\n   \\label{fig:DP_german}\n\\end{figure*}\n\n\n\\begin{figure*}[h]\n   \\centering\n   \\includegraphics[width0.24\\textwidth]{{img_pu_german_noise_est/disp_test_german,0.2,0.0,3,DP,Agarwal,3,False,test_rho_est_err}.pdf}\n   \\includegraphics[width0.24\\textwidth]{{img_pu_german_noise_est/disp_test_german,0.4,0.0,3,DP,Agarwal,3,False,test_rho_est_err}.pdf}   \n   \\includegraphics[width0.24\\textwidth]{{img_pu_german_noise_est/error_test_german,0.2,0.0,3,DP,Agarwal,3,False,test_rho_est_err}.pdf}\n   \\includegraphics[width0.24\\textwidth]{{img_pu_german_noise_est/error_test_german,0.4,0.0,3,DP,Agarwal,3,False,test_rho_est_err}.pdf}   \n   \\caption{Relationship between the estimated noise level $\\hat{\\rho}^+$ and fairness violation/error on the {\\tt german} dataset using DP constraint (testing curves). Note that $\\hat{\\rho}^-$ is fixed to 0 and $\\tau0.04$.}\n   \\label{fig:german_est_err}\n\\end{figure*}\n\n\\aditya{Placeholder, need to expand.}\n \\AKMEDIT{Figure~\\ref{fig:law_est_err_full} shows results for a range of noise levels.}\n {Figure~\\ref{fig:law_est_err_full} shows additional results under noise rate estimation on {\\tt law school} for different noise levels $\\rho^+   \\rho^- \\in \\{0.2, 0.4\\}$.}\n\n auto-ignore\n \\begin{figure*}[!t]\n   \\centering\n   \\includegraphics[width0.24\\textwidth]{{img_pu_law_noise_est/disp_test_law,0.0,0.2,1,DP,Agarwal,3,False,test_rho_est_err}.pdf}\n   \\includegraphics[width0.24\\textwidth]{{img_pu_law_noise_est/disp_test_law,0.0,0.4,1,DP,Agarwal,3,False,test_rho_est_err}.pdf}   \n   \\includegraphics[width0.24\\textwidth]{{img_pu_law_noise_est/error_test_law,0.0,0.2,1,DP,Agarwal,3,False,test_rho_est_err}.pdf}\n   \\includegraphics[width0.24\\textwidth]{{img_pu_law_noise_est/error_test_law,0.0,0.4,1,DP,Agarwal,3,False,test_rho_est_err}.pdf}\n   \\caption{Relationship between the estimated noise level $\\hat{\\rho}^-$ and fairness violation/error on the {\\tt law school} dataset using DP constraint (testing curves), with $\\hat{\\rho}^+   0$ and $\\tau0.2$.}\n   \\label{fig:law_est_err_full}\n \\end{figure*}\n\n\\clearpage\n\n\\section{The influence of different noise levels}\n\\label{appendix:noise-level}\n\nFigure \\ref{fig:diff_noise} explores the influence of the noise level on the trends and relationships between our method's performance and that of the benchmarks. We run these experiments on the UCI {\\tt adult} dataset, which is another dataset from the UCI repository ~\\citep{UCI}. The task is to predict if one has income more than 50K and gender is the sensitive attribute. The data comprises 48842 examples and 14 features. We run these experiments with the DP constraint under different CCN noise levels ($\\rho^+   \\rho^- \\in \\set{0.01, 0.1, 0.2, 0.3, 0.4, 0.48}$). We include both training and testing curves for completeness. As we can see, as the noise increases the gap between the corrupted data curves and the uncorrupted data curve increases. It becomes very hard to get close to the non-corrupted case when noise becomes too high.\n\n\\begin{figure*}[h!]\n   \\centering\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{disp_test_adult,0.01,0.01,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{error_test_adult,0.01,0.01,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{disp_train_adult,0.01,0.01,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{error_train_adult,0.01,0.01,1.0,DP,Agarwal,6,False}.pdf}\n   \n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{disp_test_adult,0.1,0.1,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{error_test_adult,0.1,0.1,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{disp_train_adult,0.1,0.1,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{error_train_adult,0.1,0.1,1.0,DP,Agarwal,6,False}.pdf}\n   \n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{disp_test_adult,0.2,0.2,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{error_test_adult,0.2,0.2,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{disp_train_adult,0.2,0.2,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{error_train_adult,0.2,0.2,1.0,DP,Agarwal,6,False}.pdf}\n   \n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{disp_test_adult,0.3,0.3,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{error_test_adult,0.3,0.3,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{disp_train_adult,0.3,0.3,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{error_train_adult,0.3,0.3,1.0,DP,Agarwal,6,False}.pdf}\n   \n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{disp_test_adult,0.4,0.4,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{error_test_adult,0.4,0.4,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{disp_train_adult,0.4,0.4,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{error_train_adult,0.4,0.4,1.0,DP,Agarwal,6,False}.pdf}\n   \n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{disp_test_adult,0.48,0.48,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{error_test_adult,0.48,0.48,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{disp_train_adult,0.48,0.48,1.0,DP,Agarwal,6,False}.pdf}\n   \\includegraphics[width0.24\\textwidth]{adult_DP_diff_levels/{error_train_adult,0.48,0.48,1.0,DP,Agarwal,6,False}.pdf}\n   \n   \n   \\caption{Relationship between input $\\tau$ and fairness violation/error on the {\\tt adult} dataset for various noise levels. From left to right: testing fairness violation, testing error, training fairness violation, and training error. Different noise levels from top to bottom.}\n   \\label{fig:diff_noise}\n\\end{figure*}\n\n\n\n\\end{appendices}",
  "title": "Noise-tolerant fair classification"
}
