{
  "authors": [
    "Alexandre Louis Lamy",
    "Ziyuan Zhong",
    "Aditya Krishna Menon",
    "Nakul Verma"
  ],
  "date_published": "2019-01-30",
  "raw_tex": "auto-ignore\n\n \\begin{figure*}[t]\n   \\centering\n   \\includegraphics[width0.4\\textwidth]{img_pu_law/{disp_test_law,0.0,0.2,1.0,DP,Agarwal,3,False}.pdf} \n   \\includegraphics[width0.4\\textwidth]{img_pu_law/{error_test_law,0.0,0.2,1.0,DP,Agarwal,3,False}.pdf}\n\n   \\caption{Relationship between input $\\tau$ and fairness violation/error on the {\\tt law school} dataset using DP constraint (testing curves).\n   The black dotted \n   {gray dashed line} represents the ideal fairness violation.\n   Note that in some of the graphs, the red line and the orange line perfectly overlap with each other.\n   \\AKMEDIT{Our method {\\sf cor scale} closely achieves approximately the ideal violation (indicated by the gray dashed line in the left panel),\n   with only a mild degradation in accuracy compared to training on the uncorrupted data (indicated by the {\\sf nocor} method in the right panel).}   \n   }\n   \\label{fig:law}\n \\end{figure*}\n\n AKM: only use #1 and #3\n emphasise directly that red line is closer to yellow\n green is super-fair and erroneous\n\\begin{figure*}[t]\n   \\centering\n   \\includegraphics[width0.4\\textwidth]{{img_pu_law_noise_est/disp_test_law,0.0,0.2,1,DP,Agarwal,3,False,test_rho_est_err}.pdf}\n   \\includegraphics[width0.4\\textwidth]{{img_pu_law_noise_est/error_test_law,0.0,0.2,1,DP,Agarwal,3,False,test_rho_est_err}.pdf}\n   \\caption{Relationship between the estimated noise level $\\hat{\\rho}^-$ and fairness violation/error on the {\\tt law school} dataset using DP constraint (testing curves), with $\\hat{\\rho}^+   0$ and $\\tau0.2$. Our method ({\\sf cor scale}) is not overly sensitive to imperfect estimates of the noise rate, evidenced by its fairness violation and accuracy closely tracking that of training on the uncorrupted data ({\\sf nocor})\n   as $\\hat{\\rho}^-$ is varied. That is, red curve in the left plot closely tracks the yellow reference curve.\n   By contrast, the baseline that explicitly denoises the data ({\\sf denoise}) deviates strongly from {\\sf nocor},\n   and is sensitive to small changes in $\\hat{\\rho}^-$.\n   This illustrates that our method performs well even when noise rates must be estimated.}\n   \\label{fig:law_est_err}\n\\end{figure*}\n\n\nTable \\ref{Tab:noise} shows the influence of this noise on the size of both sensitive groups for the training set.\n\n\\begin{table}[ht]\n\\caption{Impact of noise on two groups}\n\\centering\n\\begin{tabular}{ | l | l | l |}\n   \\hline\n   situations & $A0$ & $A1$ \\\\ \\hline\n   w/o noise & 978 & 2012 \\\\ \\hline\n   w/ noise $\\rho_a^-0.2$ & 765 & 2225 \\\\ \\hline\n   w/ noise $\\rho_a^-0.4$ & 567 & 2423 \\\\ \\hline\n\\end{tabular}\n\\label{Tab:noise}\n\\end{table}\n\nIn this case study, we consider the dataset {\\tt law school}, which is a subset of the original dataset from LSAC~\\citep{Wightman}. In this dataset, one is provided with information about various individuals (grades, part time/full time status, age, etc.) and must determine whether or not the individual passed the bar exam.\nThe sensitive feature is race; we only consider black and white.\nAfter prepossessing the data by removing instances that had missing values and those belonging to other ethnicity groups (neither black nor white) we were left with 3738 examples each with 11 features. \n\nWhile the data ostensibly provides the true values of the sensitive attribute, one may imagine having access to only PU information.\nIndeed, when the data is collected one could imagine that individuals from the minority group would have a much greater incentive to lie about\n{conceal} their group membership due to fear of discrimination.\n Note that there would be no similar incentive if belonging to the majority group.\nThus, any individual identified as belonging to the majority group could be assumed to have been correctly identified (and would be part of the positive instances).\nOn the other hand, no definitive conclusions could be drawn about individuals identified as belonging to the minority group (these would therefore be part of the unlabelled instances). \n\nTo model a PU learning scenario, we added CCN noise to the dataset with $\\rho^+   0$ and \n$\\rho^- \\in \\set{0.2, 0.4}$. \n{$\\rho^-   {0.2}$.}\n Again, we perform fair classification on this noisy dataset with DP as the constraint. \n We use our method as well as the three benchmarks described above.\nWe initially assume that the noise rate is known. (some kind of perfect estimator is available).\nFigure \\ref{fig:law} shows the average result over three runs under this setting each with a random 80-20 training-testing split. \n{We draw the same conclusion as before:\nour method\nachieves the highest accuracy while\nrespecting the specified fairness constraint.\n nearly achieves the ideal fairness violation, \n while only slightly degrading in terms of accuracy.\n Further, the other baselines yield worse tradeoffs than our method.\n}\n As before, it can be seen that the na\\\"{i}ve method {\\sf cor} violates the fairness constraint while our method {\\sf cor scale} reaches a degree of fairness violation which is very close to the level reached by the fair classifier when there is no noise ({\\sf nocor}).\n Although the method {\\sf denoise} seems to also achieve the desired fairness level, it does so by sacrificing much more accuracy than our method.\n\nUnlike in the privacy case, the noise rate in the PU learning scenario is usually unknown in practice,\nand must be estimated.\nMany methods exist that can be used to estimate the noise rate.\n{Such estimates will inevitably be approximate.}\nWe thus evaluate the impact of the error of the noise rate estimate on all methods.\nin terms of accuracy and fairness violation.\n{In Figure~\\ref{fig:law_est_err}, we consider a PU scenario where \n$\\rho^+0$ is known, but \nwe only have access to an estimate $\\hat{\\rho}^-$ of the negative noise rate,\nwhose true value is $\\rho^-   0.2$.}\nFigure \\ref{fig:law_est_err} shows the impact of different values of $\\hat{\\rho}^-$ on the fairness violation and error.\nWe see that that as long as this estimate is reasonably accurate, \nour method performs the best in terms of being closest to the case of running the fair algorithm on uncorrupted data.\n\n\\aditya{Minimizing, US english.}\nIn sum,\nthese results are consistent with our derivation and show that our method {\\sf cor scale} can achieve the desired degree of fairness while minimising loss of accuracy.\nAppendix \\ref{appendix:pu} includes results for different settings of $\\tau$, noise level, and on other datasets showing similar trends.\n",
  "title": "Noise-tolerant fair classification"
}
