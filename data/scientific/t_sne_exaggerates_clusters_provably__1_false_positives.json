{
  "authors": [
    "Noah Bergam",
    "Szymon Snoeck",
    "Nakul Verma"
  ],
  "date_published": "2025-10-09",
  "raw_tex": "\\todo[inline]{Rewrite so that it is not just the abstract restated.}\nSuccess in practice and heuristic arguments, like the above, have inspired a widespread belief that t-SNE visualizations preserve the cluster structure of the input. To the contrary, we prove that the strength of the input clustering cannot be reliably inferred from the low-dimensional visualization.\n\n\n\nHeuristic arguments, like the above, and success in practice and have inspired a widespread belief that the cluster structure present in t-SNE visualizations is in correspondence with the cluster structure of the input. \nThe practical success and appeal of t-SNE has inspired a b\n\nSuppose you have two datasets, and their t-SNE plots strongly suggest not only that the datasets are clustered but that they obey similar clusterings.\n\nPrevious works by \\citet{linderman2019clustering} and \\citet{arora2018analysis} have identified that clustered inputs induce clustered t-SNE visualizations in a suitable sense. A key question for practitioners left unanswered by these analyses is: when does a clustered output imply a clustered input? \nDoes a t-SNE output appear clustered if and only if the input is clustered? \nMore generally, what information can be deduced about the input given a visualization? We answer this question by providing theoretical and practical evidence that the strength of cluster structure in the input cannot be reliably inferred from the low-dimensional visualization. In particular, we prove that (i) similarly clustered t-SNE visualizations do not imply similarly clustered inputs, and (ii) distinctly clustered visualizations do not imply distinctly different inputs. \n\nsimilarly clustered outputs /> similarly strong clustering in input space.\n\ndifferently clustered outputs /> far apart inputs.\n\n\nCentral to the widespread use of t-SNE and related methods is the conviction that they produce visualizations whose cluster structure roughly matches that of the input. To the contrary, we prove that the strength of the input clustering cannot be reliably inferred from the low-dimensional visualization.\n\n\\todo[inline]{Add the definitions of the cluster indexes to appendix.}\nTo quantify the strength of the cluster structure in a dataset, we study\nemploy\nwell-known cluster indices such as the average silhouette score \\citep{rousseeuw1987silhouettes}, the Calinski-Harabasz index \\citep{Cali\u0144ski01011974}, and the Dunn index \\citep{DunnIndex1974}. \nAt their core, these indices measure the cluster partition's salience by producing some ratio of inter-cluster and   intra-cluster distances. \nFor sake of readability, we focus on presenting our results with respect to the average silhouette score. Our results hold identically for the other indices as well (see Appendix \\ref{sec:appendix_false_pos}). \n\n, we focus on the Average Silhouette Score for the sake of presentation. The formal definitions and associated theorems of the other two indices can be found in Appendix \\ref{sec:appendix_false_pos}. \n\n\\todo[inline]{Finish adding other two indices to appendix.}\n\nFor an $n$-point dataset $\\mathcal{X}   \\{x_1, \\dots, x_n\\} \\subset \\mathbb{R}^{n-1}$ and a partition of the dataset into clusters $C_1 \\sqcup C_2 \\sqcup \\dots \\sqcup C_k   [n]$\\footnote{In alignment with our usage of the cluster indexes and to avoid division by zero, we assume that for all $m \\in [k], |C_m|>1$. {\\color{red} Rewrite proof so this can be removed.}}, we denote the three indexes as $\\bar{\\mathcal{S}}(\\mathcal{X}; C_{m\\in[k]})$, -, and - for the Average Silhouette Score, the Calinski-Harabasz index, and the Davies-Bouldin index, respectively. You can see the range of each index in Table \\ref{table:demo}.\n\n\\begin{definition}\n   Given a partition $C_1 \\sqcup C_2 \\sqcup \\dots \\sqcup C_k   [n]$ of $n$ points $\\{x_1,\\ldots,x_n\\}   X$, the \\textbf{silhouette score} of a point $x_i$ (w.r.t.\\ the partition), denoted \\(\\mathcal{S}(i)\\), is the normalized difference between the average within- and the closest across-cluster distances from $x_i$: \n$$\n\\mathcal{S}(i) : \\frac{b(i)-a(i)}{\\max \\{b(i),a(i)\\}} \n\\hspace{0.25in}\na(i) : \\sum_{j \\in C^{(i)}} \\frac{\\lVert x_i - x_j \\rVert}{|C^{(i)}|-1} \n\\hspace{0.25in}\nb(i) : \\min_{\n\\substack{m \\in [k] \\\\ C_m \\neq C^{(i)}}} \\sum_{j \\in C_m} \\frac{\\lVert x_i - x_j \\rVert}{|C_m|},\n$$\nwhere $C^{(i)}$ is the cluster to which $i$ belongs. Note that if $|C^{(i)}|1$, then $\\mathcal{S}(i)$ is defined to be zero.\nThe \\textbf{average silhouette score} then is simply the average across all points in $X$:\n$$\\bar{\\mathcal{S}}(X; C_{m\\in[k]}) : \\frac{1}{n} \\sum_{i \\in [n]} \\mathcal{S}(i).$$\n\\end{definition}\nObserve that the (average) silhouette score ranges from $-1$ to $1$ with a score of $1$ being assigned to maximally clustered data, $-1$ to incorrectly clustered data, and $0$ to unclustered data.\n\n\n\\iffalse\nFor an $n$-point dataset $X   \\{x_1, \\dots, x_n\\} \\subset \\mathbb{R}^{n-1}$ and its partition into clusters $C_1 \\sqcup C_2 \\sqcup \\dots \\sqcup C_k   [n]$, the Silhouette Score of a point $x_i$ measures the difference between the average distance from $x_i$ to points in same cluster and $x_i$ to points in another cluster. Specifically, for $i\\in [n]$, let $C(i) \\in \\{C_1,\\ \\dots,\\ C_k\\}$ be the cluster to which $i$ belongs $(\\textup{i.e. } i \\in C(i))$. Then, for $|C(i)|>1$, the average distance of $x_i$ to its own cluster is:\n $$a(i) : \\frac{1}{|C(i)|-1} \\sum_{j \\in C(i)} \\lVert x_i - x_j \\rVert^2,$$\nthe average distance to the nearest distinct cluster is:\n$$b(i) : \\min_{m \\in [k] : C_m \\neq C(i)} \\frac{1}{|C_m|} \\sum_{j \\in C_m} \\lVert x_i - x_j \\rVert^2,$$\nand the Silhouette Score of $i \\in [n]$ is:\n $$\\mathcal{S}(i) \\equiv \\frac{b(i)-a(i)}{\\max \\{b(i),a(i)\\}}.$$\nIf $|C(i)|1$, then $\\mathcal{S}(i)$ is defined to be 0.\nTo measure the prevalence of cluster structure across the entire dataset, we define the Average Silhouette Score of $\\mathcal{X}$ with respect to $C_1, \\dots, C_k$ as:\n\n$$\\bar{\\mathcal{S}}(\\mathcal{X}; C_{m\\in[k]}) \\equiv \\frac{1}{n} \\sum_{i \\in [n]} \\mathcal{S}(i).$$\n\n$\\bar{\\mathcal{S}}(\\mathcal{X}; C_{m\\in[k]})$ ranges from $-1$ to $1$ with a score of $1$ being assigned to maximally clustered data, $-1$ to incorrectly clustered data, and $0$ to unclustered data. \n\n\\fi\n\n\n\nDefining the strength of a clustering with respect to this cluster index, we show that any stationary t-SNE output can be produced by an arbitrarily unclustered input:\nThis result can be generalized to any visualization produced by t-SNE or UMAP:\n\n\\begin{restatable}{theorem}{UnclustHammer} \n\\begin{theorem}\n\\label{thm:unclustHammer}\n   Fix any $n > k > 1$, and $n$-point dataset $X \\subset \\mathbb{R}^{n-1}$ with partition $C_1 \\sqcup \\cdots \\sqcup C_k   [n]$ such that $|C_{m\\in[k]}| > 1$ and $\\bar{\\mathcal{S}}(X; C_{m\\in[k]})$ is well defined. For all $0 < \\epsilon \\leq 1$, there exists $n$-point dataset $X_\\epsilon \\subset \\mathbb{R}^{n-1}$ such that \n   $$\\bar{\\mathcal{S}}(X_\\epsilon; C_{m\\in[k]})   \\epsilon \\cdot \\bar{\\mathcal{S}}(X; C_{m\\in[k]}), $$\n   yet, for any $\\rho \\in (1, n-1)$:\n   $${\\TSNE}_\\rho(X)   {\\TSNE}_\\rho(X_\\epsilon).$$\n\\end{theorem}\n\\end{restatable}\nIt is important to understand the implications of this result. For any high-dimensional dataset $X$ (regardless of how clustered it is), we can find an arbitrarily unclustered impostor dataset $X_\\epsilon$ such that \\emph{all} t-SNE stationary points (local as well as global) of $X$ and $X_\\epsilon$ match perfectly! In other words it is \\emph{impossible} to distinguish between $X$ and $X_\\epsilon$ based on the low-dimensional t-SNE visualization.\n\n\\begin{figure}[t!]\n   \\centering\n   \\includegraphics[width\\linewidth]{images/rna/MAIN-single-cell.png}\n   \\vspace{-0.15in}\n   \\caption{\n   \\small\n   Visualizations of single-cell data (top row) versus an arbitrarily unclustered impostor dataset (bottom row).\n   Based on the 2D t-SNE visualization (left column), it is difficult do distinguish which dataset (real or impostor) may have produced the plot. Plotting the high-dimensional interpoint distances (right column) confirms that the imposter dataset is unclustered in some sense. As a reference we also plot the 2D PCA visualization (center column) to indicate that this issue does not occur with other methods. The numbers on the bottom left of each figure shows the cluster salience in terms of the average silhouette score for the 2D t-SNE plot (left), 2D PCA plot (center), and high-dimensional input (right) for the real dataset (top) and the impostor dataset (bottom).\n   The top row of plots are generated from a preprocessed version of the PBMC3k dataset, which consists of $2638$ points in $\\mathbb{R}^{50}$. The colored clustering in all plots corresponds to a DBSCAN clustering of the top left plot. The bottom row describes a different dataset which is much closer to a regular simplex, yet yields a remarkably similar t-SNE plot. Note the distinction between the similarity of the t-SNE plots and the difference of the PCA plots. \n   Note that the color coding in all of the scatter plots corresponds to a DBSCAN clustering \\citep{ester1996density} of the top left t-SNE plot.} \n   \\vspace{-0.1in}\n   \\label{fig:single_cell_false_pos}\n\\end{figure}\n\n\nAs a consequence, the same maximally clustered visualization can be produced by a sequence of impostor datasets ranging from maximally clustered to arbitrarily unclustered,\n\\begin{restatable}{corollary}{TwoClusterNUnclustered} \n\\begin{corollary}\n\\label{cor:twoCluster_n_Unclustered}\n   For all $n \\geq 4$ even, and partition $C_1 \\sqcup C_2   [n]$ such that $|C_1||C_2|\\frac{n}{2}$.\n   \\todo{Since t-SNE/UMAP is going into 2D, can maybe get away with k3 and even clusters. This may also open questions about up to how many clusters this holds true for tho.}\n   There exist a sequence of $n$-point datasets in $\\mathbb{R}^{n-1}$, $\\{ X_\\epsilon\\}_{0 < \\epsilon \\leq 1}$, with \n   $$\\bar{\\mathcal{S}}(X_\\epsilon; C_1,C_2)   \\epsilon$$\n   such that for any $\\rho \\in (1, n-1)$, we have $Y\\in \\bigcap_{0<\\epsilon \\leq 1}{\\TSNE}_\\rho(X_\\epsilon)$ with\n   $$\\bar{\\mathcal{S}}(Y; C_1,C_2)   1.$$ \n\\end{corollary}\n\\end{restatable}\nThe above shows that $Y$, a perfectly clustered visualization, is a local (and   global, see the proof in Appendix) \\footnote{See proof of Corollary \\ref{cor:twoCluster_n_Unclustered}.} \nminimizer for any member of a set of inputs that range from being maximally clustered to being arbitrarily unclustered. Thus, even from a \\emph{perfectly} clustered visualization, the strength of the input's cluster structure cannot be inferred. \n\n\n\n\n\nNote that the existence of an impostor $X_\\epsilon$ is not just theoretical; it can be constructed practically as well (see Appendix \\ref{app:impostor_construction} for an explicit construction). Hence this phenomenon can be demonstrated in real-world scenarios, see Figure \\ref{fig:single_cell_false_pos}. \nIn this case, we select a preprocessed version of the well-known PBMC3k single-cell genomics dataset ($2638$ points, $50$ dimensions; \\citet{single_cell}) as $X$. We show that there is an arbitrary unclustered impostor dataset $X_\\epsilon$ that is essentially indistinguishable from the real dataset in terms of its 2D t-SNE visualization. In short, similarity in t-SNE visualization does not necessarily imply similarity in the input space.\n\n\nThis fact is by no means limited to hand-picked datasets used in proofs.\n\\textcolor{red}{TALK ABOUT PRACTICAL DATA AND FIG 1.}\nThe phenomenon can be observed in natural high-dimensional data such as that generated by a mixture of Gaussians and Student's t-distributions (see Figure \\ref{fig:higher_dim_tighter_clusters}). In the figure, the visualizations of the two inputs appear equally clustered in spite of the fact that the Average Silhouette Score of the mixture of Student's t-distributions is 10 times that of the mixture of Gaussians. In short, similarity in t-SNE visualizations does not guarantee similarity in the input space.\n\n\n\n\n\n\n\n\nSymmetrically, similarity in the input space does not guarantee similarity in the t-SNE visualizations. In fact, any two drastically different visualizations can be produced by arbitrarily close inputs:\n\\begin{restatable}{theorem}{Perturbhammer}\n\\label{thm:perturbhammer}\n   Fix any $n > 2$ and $\\rho \\in (1, n-1)$. For all $\\epsilon>0$ and all $Y, Y' \\in {\\IMTSNE}$, there exists $n$-point datasets $X   \\{x_1,\\ldots,x_n \\}$ and $ X'\\{x'_1,\\ldots,x'_n\\} \\subset \\mathbb{R}^{n-1}$ such that $\\forall i\\neq j$\n   $$1 - \\epsilon \\leq \\frac{\\lVert x_i - x_j \\rVert^2}{\\lVert x'_i - x'_j \\rVert^2} \\leq 1 + \\epsilon,$$\n yet $Y \\in {\\TSNE}_\\rho(X)$ and \n   $Y' \\in {\\TSNE}_\\rho(X').$\n\\end{restatable}\nThus even minor perturbations of the input dataset can develop into massive changes in the visualization. Figure \\ref{fig:sameIn_diffOut} demonstrates this phenomenon quite clearly. We start with a dataset $X$ that is a regular unit simplex (all pairwise distances are unit length). By systematically perturbing the input $X$ ever so slightly ($\\epsilon\\leq 0.01$), t-SNE produces strikingly different outputs. \n\nThe key observation behind our main Theorems \\ref{thm:unclustHammer} and \\ref{thm:perturbhammer} is the simple yet counter-intuitive fact\\footnote{To the best of our knowledge, no theory or practical work on t-SNE has studied this observation formally.} that t-SNE is not only invariant under multiplicative scaling of the input squared distances, but also additive scaling of these distances. Specifically given a dataset $X\\{x_1,\\ldots,x_n\\}$, for any dataset $X'\\{x'_1,\\ldots,x'_n\\}$ and $C \\in \\R$ such that, $ \\lVert x'_i-x_j' \\rVert^2   \\lVert x_i-x_j \\rVert^2+C \\geq 0$ for $i \\neq j$, we have $\\TSNE_\\rho(X)   \\TSNE_\\rho(X')$ (see Lemma \\ref{lem:tSNE_additive_invariance} for a formal statement). As a consequence, for any input dataset, we can simply pump up the interpoint distances and construct an impostor dataset which has the same visualization profile but is arbitrarily close to a regular simplex (and hence is arbitrarily unclustered)\\footnote{See Algorithm \\ref{alg:impostor} for a formalization of this process.}.   entire t-SNE stationary point (hence the visualization) profile. \nThis observation also leads to the following seemingly bizarre fact. a surprising fact about the set of all t-SNE outputs.\nidea is formalized in a key lemma below which is also utilized to prove our main Theorems \\ref{thm:unclustHammer} and \\ref{thm:perturbhammer}.\n\n\\begin{figure}\n   \\centering\n   \\includegraphics[width1\\linewidth]{images/Same_input_diff_out_0.008_9_21_25_wAmongus.png}\n   Similar inputs with vastly different visualizations.}\n   \\vspace{-0.15in}\n   \\caption{\n   \\small\n   Myriad 2D t-SNE visualizations, all produced by small perturbations of the same 200-point input dataset. \\textcolor{red}{FIX THIS} high dimensional Gaussian.\n   Similar inputs with vastly different visualizations. \n   The t-SNE visualization of five different \n   Each perturbation satisfies the conditions of Theorem \\ref{thm:perturbhammer} for $\\epsilon   0.01$.}\n   \\vspace{-0.1in}\n   \\label{fig:sameIn_diffOut}\n\\end{figure}\n\n\n\n\n\n\\begin{lemma}\\label{lem:image_of_tSNE}\n   Fix any $n > 2$ and $\\rho \\in (1, n-1)$. For any $\\epsilon>0$, define the set of $\\epsilon$-perturbations of a unit simplex as $\\Delta_\\epsilon : \\{ X\\{x_1, \\dots, x_n\\} \\subset \\mathbb{R}^{n-1}: \\forall i\\neq j, \\lVert x_i - x_j \\rVert^2 \\in [1-\\epsilon, 1+\\epsilon]\\}$. Then, for all $\\epsilon>0$\n   $${\\IMTSNE}   {\\TSNE}_\\rho(\\Delta_\\epsilon).$$\n\\end{lemma}\n\\todo[inline]{Corollary of this section is the perturbation result: As a consequence of this ``cluster exaggeration'', highly clustered visualizations can easily be perturbed by small changes in the input.}\nThe key to understanding why this lemma holds is the \\emph{additive invariance} property of t-SNE. \nIn other words, there is a set of datasets \\(\\Delta_\\epsilon\\) arbitrarily close to a regular unit simplex that generates \\textit{all} possible stationary t-SNE outputs! The instability of t-SNE on such datasets (c.f.\\ Figure \\ref{fig:sameIn_diffOut}) has real-world consequences since many high-dimensional datasets fall into this regime \\citep{conc_hd_dist_1, aggarwal2001surprising} due to the concentration of measure phenomenon \\citep{ledoux2001concentration}. In particular, such datasets are susceptible to single-point adversarial attacks. Consider a dataset $X$ sampled from a mixture of two high-dimensional Gaussians. t-SNE, as expected, reveals the two underlying clusters (c.f.\\ Figure \\ref{fig:one_pt_perturb}, first panel). However, we can add just a single ``poison\" point to $X$ and destroy the clustered visualization (see Figure \\ref{fig:one_pt_perturb} second panel). This failure mode of t-SNE is also observed on a real high-dimensional datasets (see Figure \\ref{fig:outliers_real_world} left vs.\\ center).\n\nThe success of the poison point attack can be attributed to additive invariance. Given an input dataset in \\(\\Delta_\\epsilon\\) from a clustered, high-dimensional distribution, the set of interpoint distances occupy a tight band between $1-\\epsilon$ and $1+\\epsilon$. Since t-SNE is invariant under additive scaling, the dataset appears identically as if all the distances are in the range $[0, 2\\epsilon].$ Thus, from t-SNE's perspective, the variation between inter-cluster distance ($\\approx 2\\epsilon$) and intra-cluster ($\\approx 0$) is large. However, when the poison point is added at the mean, the minimum distance from any point to the rest of the set is approximately halved. As a result, almost all distances remain in the range $[1-\\epsilon, 1+\\epsilon],$ but, as t-SNE sees it, the effective inter-cluster ($\\approx (1+\\epsilon) - \\frac{1}{2}(1-\\epsilon)   \\frac{1}{2}+\\frac{3}{2}\\epsilon$) and intra-cluster ($\\approx (1-\\epsilon) - \\frac{1}{2}(1-\\epsilon)   \\frac{1}{2}-\\frac{1}{2}\\epsilon$) gap has been reduced, causing the cluster structure to go unrecognized in some cases.\n\nIn the next section, we explore this phenomenon on a real-world dataset (Figure \\ref{fig:outliers_real_world}), where we contrast it with t-SNE's strikingly indifferent response to the injection of outlier points. \n\nwe can think of t-SNE as constructing a visualization based on a set of interpoint distances occupying a tight band, say between \\(1-\\epsilon\\) and \\(1+\\epsilon\\). If the dataset is clustered, there are \n\n\nue to additive invariance, it is effectively looking at a shifted version of this set, ranging from \\(0\\) to \\(2\\epsilon\\). Injecting a poison point changes this calculus, by lowering the minimum interpoint distance to say \\(0.5\\). The effective range becomes \\([0, 0.5 + 2\\epsilon]\\). The interpoint distances In turn, naturally occurring structure in the visualization can be washed-out by adding a single ``poison point''. \n\nsubstantially \\emph{lowers} the minimum interpoint distance, say from \\(1\\) down to \\(0.5\\), then the effective range becomes $0$ to $0.501$. In turn, naturally occurring structure in the visualization can be washed-out by adding a single ``poison point''. \n\nanalyzing its tight band of interpoint distances, say between \\(1\\) to \\(1 + \\epsilon\\), and, due to additive invariance, can be treated as if they ranged from \\(0\\) to \\(\\epsilon\\). Injecting a poison point substantially   \\emph{lowers} the minimum interpoint distance, say from \\(1\\) down to \\(0.5\\), then the effective range becomes $0$ to $0.501$. In turn, naturally occurring structure in the visualization can be washed-out by adding a single ``poison point''.   \nWe can begin to explain the outsize influence of the poison point from the perspective of additive invariance. The basic idea here is that t-SNE Consider how t-SNE processes a low-aspect ratio dataset. Given some set of interpoint distances in a narrow band, say \\([1, 1+\\epsilon]\\), it processes these distances as if they belonged to \\([0,\\epsilon]\\), via additive invariance. We explore this phenomenon further in the next section, where we contrast it with t-SNE's strikingly indifferent response to the injection of outlier points . \n\n\n\nGiven an input from such high-dimensional data, we can think of t-SNE as analyzing its tight band of interpoint distances, say between \\(1\\) to \\(1.001\\), and treating it as if it ranged fo \\(0\\) to \\(0.001\\) due to additive invariance. This suggests a weakness of t-SNE to a certain kind of adversarial perturbation: if one injects a point into this dataset which substantially \\emph{lowers} the minimum interpoint distance, say from \\(1\\) down to \\(0.5\\), then the effective range becomes $0$ to $0.501$. In turn, naturally occurring structure in the visualization can be washed-out by adding a single ``poison point''. \n\n\nsuch that t-SNE outputs a single cluster.   However an introduction of just a single adversarial point to alter interpoint distance results in a dramatic collapse of the global structre (figure middle) \n\n\nOne should one that most high-dimensional datasets occupy this unstable \\(\\Delta_\\epsilon\\) region. This idea is well-studied \nin previous work in database theory \\citep{conc_hd_dist_1, aggarwal2001surprising} and high-dimensional statistics \\citep{ledoux2001concentration}.\n\n\nSuch datasets constitute an unstable part of the t-SNE input landscape, per Figure \\ref{fig:sameIn_diffOut}.\n\nThis is quite a practical observation insofar as many real-world datasets belong to \\(\\Delta_\\epsilon\\).\n\nThe t-SNE visualization of such datasets in $\\Delta_\\epsilon$ are also susceptible to single-point perturbations. Consider a $X \\in \\Delta_\\epsilon$ such that $\\TSNE(X)$ displays two clear clusters. We claim that one can add a single point to this dataset which renders the t-SNE output un-clustered! \n\nHow is this possible? To see this, think of t-SNE as operating on just the interpoint distances. Given the aforementioned \\(X\\), it takes in a band of distances between say \\(1-\\epsilon\\) and \\(1+\\epsilon\\) and by additive invariance \n\n\n\nConsider, for instance, introducing a single adversarial point. This point can be chosen to significantly alter the distribution of interpoint distances, having an outsize effect on the t-SNE output. \n\n\nThis small ball \\(\\Delta_\\epsilon\\) is also an unstable part of the input landscape on multiple levels. As shown in Figure \\ref{fig:sameIn_diffOut}, an adversary making small changes to each of the interpoint distances can change t-SNE plots . We also observe \n\n\nThis is good news for an adversary, in the sense that this small ball of inputs \\(\\Delta_\\epsilon\\) is unstable with respect to small perturbations of the points, per Figure \\ref{fig:DiffIn_SameOut}. \n\n\nAs seen in Figure \\ref{fig:DiffIn_SameOut}, an adversary\n\n\n\nIt stands to reason that even adding a single point to such a dataset\n\nMoreover, even single-point changes to such inputs can have outsize effects. \n\n\n\n\n\nFor instance, consider adding a point at the center of a sample of a mixture of two high-dimensional Gaussians. \n\n\n\nsuch inputs are susceptible to an eve, more insidious kind of adversarial perturbation: namely, the injection of a single point. \nThis means inputs to t-SNE which are close to a simplex are particularly unstable: small changes in the t-SNE input can yield radically different-looking outputs. This is in contrast to say, PCA, which depicts such datasets\nThe additive invariance property and its consequences have an interesting interplay with the fact that most high-dimensional datasets do in fact reside in \\(\\Delta_\\epsilon\\) for small \\(\\epsilon\\).\nIt stands to reason that slight perturbations of datasets residing in \\(\\Delta_\\epsilon\\) can potentially have outsize effects on the t-SNE. Consider, for instance, adding a single point. \nGiven an input from \\(\\Delta_\\epsilon\\), we can think of t-SNE as analyzing its tight band of interpoint distances, say between \\(1\\) to \\(1.001\\), and treating it as if it ranged fo \\(0\\) to \\(0.001\\) due to additive invariance. This suggests a weakness of t-SNE to a certain kind of adversarial perturbation: if one injects a point into this dataset which substantially \\emph{lowers} the minimum interpoint distance, say from \\(1\\) down to \\(0.5\\), then the effective range becomes $0$ to $0.501$. In turn, naturally occurring structure in the visualization can be washed-out by adding a single ``poison point''. this may change the calculus dramatically.\n\\sout{We observe {\\color{red} this phenomena} in both synthetic and real data that the introduction of such a ``poison point'' can have an outsize effect on t-SNE output}. \n\nThis is perhaps most dramatic in Figure \\ref{fig:one_pt_perturb}, where injecting a single ``poison'' point at the mean of a mixture of two high-dimensional Gaussians destroys the cluster separation of the t-SNE output entirely. We explore this phenomenon further in the next section, where we contrast it with t-SNE's strikingly indifferent response to the injection of outlier points. \n\n\n\nOne should one that most high-dimensional datasets occupy this unstable \\(\\Delta_\\epsilon\\) region. This idea is well-studied \nin previous work in database theory \\citep{conc_hd_dist_1, aggarwal2001surprising} and high-dimensional statistics \\citep{ledoux2001concentration}.\n\n\n\nphenomenon in the theory of high-dimensional probability, closely related to the concentration of measure phenomenon (e.g.\\ some illustrative example about gaussians) \n\\citep{ledoux2001concentration}. (citation that highD data is appox simplex)\n\n\nGiven a high-dimensional dataset, t-SNE is agnostic to the \\textit{magnitude} of the minimum interpoint distance. This may allow t-SNE to zero in some structure that \n\nIt also suggests an Achilles heel: perturbing the moinimum interpoint distance using an adversarial injection point.\n\n\n\nAnother curious effect of additive invariance is t-SNE's sensitivity to changes in the minimum interpoint distance by adding/moving? a single point.   can stop t-SNE from recognizing the cluster structure at all. This is most dramatically shown in Figure \\ref{fig:one_pt_perturb} where injecting a single ``poison'' point at the mean of a mixture of two Gaussians destroys the cluster structure entirely. We explore this phenomenon further in the next section, where we contrast it with t-SNE's significantly more indifferent response to the injection of far away outliers.\n\n \nThis fact reveals that t-SNE is un\n\n whose image under t-SNE is surjective to the \\emph{entire} t-SNE image for all possible inputs! \n\n\\todo[inline]{READ ABOVE}First, we introduce some notation:\n\n\n\nLemma \\ref{lem:X+C_exists} guarantees that $X_{+C}$ always exists. We say that a data visualization algorithm is \\emph{invariant to additive scaling} if for all $C \\geq 0$ and $n$-point inputs, $X \\subset \\mathbb{R}^{n-1}$, the algorithm produces the same output on $X$ and $X_{+C}.$ Using additive invariance, we can make any input arbitrarily unclustered while preserving the output visualization. Indeed, by increasing the strength of the additive scaling, the ratio between any two distinct distances in the input goes to 1. \nIn turn, the cluster structure loses its prominence while the output is maintained. This is the key insight behind Theorem \\ref{thm:unclustHammer}. Theorem \\ref{thm:additiveInvariance} also shows that Theorem \\ref{thm:unclustHammer} actually holds for a large variety of algorithms.\n\nThis observation also puts forth an alternative interpretation of these algorithms. Because they are invariant under additive scaling, any input, $\\mathcal{X}$, registers to the algorithm as a condensed version where the minimum distance is subtracted off, i.e., with some mild abuse of notation,\n$$\\text{t-SNE}_\\rho(\\mathcal{X})   \\text{t-SNE}_\\rho(\\mathcal{X}_{-\\min_{x \\neq x'\\in \\mathcal{X}} \\lVert x-x'\\rVert^2}).$$\n\nThe additive invariance property can make the input seem more clustered than it actually is, especially if the aspect ratio is close to 1. \nIt is worth noting The NLP dataset from Figure \\ref{fig:higher_dim_tighter_clusters} exemplify this trend. As the dimension of the sample increases, concentration of measure causes the inter-cluster and intra-cluster distances to converge to their expectations. Since the intra-cluster distances will all be close to the minimum distance, the algorithm perceives the input as if the clusters are contracted. Hence, seemingly less clustered inputs, i.e. close to a simplex, can get more clustered outputs.\n\nThe additive invariance property of t-SNE has an interesting interplay with the \\textit{concentration of measure phenomenon}, which, broadly speaking, tells us that high-dimensional data tends to look approximately like a regular simplex. From a practical perspective, \n\n\nAdditionally, perturbing the minimum distance by adding a single outlier can stop t-SNE from recognizing the cluster structure at all. This is most dramatically shown in Figure \\ref{fig:one_pt_perturb} where injecting a single ``poison'' point at the mean of a mixture of two Gaussians destroys the cluster structure entirely.\n\n\\begin{figure}\n   \\centering\n   \\includegraphics[width\\linewidth]{images/outlier_figs/one_pt_perturb.png}\n   \\vspace{-0.15in}\n   \\caption{   \\small\n   t-SNE versus PCA plots in response to the injection of a single ``poison'' point in the input dataset. The original dataset, visualized in panels 1 and 3, consists of \\(400\\) points sampled from a mixture of two well-separated Gaussians in \\(\\mathbb{R}^{2000}\\). The poison point is then placed at the mean of the previously sampled points; the resulting $401$-point dataset is visualized in panels 2 and 4. \n   }\\label{fig:one_pt_perturb}\n   \\vspace{-0.1in}\n\\end{figure}\n\n\n\n\n\n\n\n\\todo[inline]{Add discussions of expansions of Theorem \\ref{thm:unclustHammer} to other data visualization methods and cluster indices due to the widespread applicability of the proof technique.}\n\n",
  "title": "t-SNE exaggerates clusters, provably"
}
