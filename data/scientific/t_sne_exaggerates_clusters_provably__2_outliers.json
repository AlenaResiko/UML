{
  "authors": [
    "Noah Bergam",
    "Szymon Snoeck",
    "Nakul Verma"
  ],
  "date_published": "2025-10-09",
  "raw_tex": "\n\nMost analysis on t-SNE, including the previous section, is concerned with whether it faithfully depicts global structure, specifically cluster structure. In this section, we consider how t-SNE represents points that drastically deviate from the global structure: namely, \\textit{outliers}. It is natural to hope that data visualization methods can enable the identification of outliers. Unfortunately, we find that t-SNE cannot fulfill this desideratum, as it arbitrarily suppresses the severity of outliers in its depiction of certain datasets.\nThe previous section studied that t-SNE is invariant under certain \\textit{global} transformations of the input dataset. This \n\n\nIn particular, we prove that stationary t-SNE plots are liable to dramatically misrepresent the structure of data when it comes to \\textit{outliers}, i.e. points lying significantly far away from the rest of the point cloud. {\\color{red} Strengthen the above and give more introduction before u start explaining what is going on.}\nOne of the difficult truths of studying real-world data is the presence of outliers, i.e.\\ data points which do not conform to the behavior of the bulk of the data. Geometrically, one can define an outlier as a point lying significantly far away from the rest of the point cloud. It is natural to hope that data visualization techniques would visualize outliers as such.\n\nAn intuitive explanation of this phenomenon can be made based on the asymmetry of the input and output affinity matrices of t-SNE. Roughly speaking, the input affinity behaves like a normalized, symmetrized nearest neighbor graph, where the log of the perplexity roughly corresponds to the number of neighbors. Meanwhile, the output affinity behaves more like a radius neighborhood graph, at least in the sense that each point's neighborhood scale is the same. This means the output affinity is optimized to represent the outlier point in close proximity with at least some points, even if it was extremely far from those points in the input. This means the input affinity records an outlier\u2013\u2013\u2013even a very extreme one\u2013\u2013\u2013as having some set of neighbors. The output affinity is optimized to respect this, and hence places the outlier close to some points. \n\nTo begin to formalize this observation, we provide a geometric definition of an outlier.\n\n\\begin{definition}\\label{def:alpha_outlier}(\\(\\alpha\\)-outlier configuration) \nFix \\(X \\subset \\mathbb{R}^D\\), \\(x_0\\in \\mathbb{R}^D\\), and \\(\\alpha \\in \\mathbb{R}_+\\). We say \\(X\\) is an \\textbf{\\((\\alpha, x_0)\\)-outlier configuration} if there exists a hyperplane separating \\(x_0\\) and \\(X\\setminus \\{x_0\\}\\) with margin width at least \n   \\begin{equation*}\\label{eq:alpha_margin}\n   \\alpha \\cdot \\max\\{1, \\diam(X\\setminus\\{x_0\\}) \\},\n   \\end{equation*}\ni.e., there exists a unit vector \\(v \\in \\mathbb{R}^D\\) such that for all \\(x\\in X\\setminus\\{x_0\\}\\), \\((v-x_0)\\cdot (x-x_0)\\) is at least the above.   \n   \\textcolor{red}{use max}\n   \\textcolor{red}{do a plus 1. this will make the proof much easier. avoids issues with diameter   0.}\n Define the \\textbf{outlier number} of a dataset\\todo{Measure might be an overloaded word in a math context?}\n , denoted \\(\\alpha(X)\\), as the largest \\(\\alpha\\) for which there exists \\(x_0 \\in X\\) such that \\(X\\) is an \\((\\alpha, x_0)\\)-outlier configuration.\n\\end{definition}\n\nThis definition can be generalized to accommodate more than one outlier, but for the purposes of theoretical analysis we consider just one. Note that the outlier extremity \\(\\alpha\\) is defined relative to the diameter of the rest of the points, unless that diameter is below \\(1\\). The choice of a threshold here is important and intuitive: it allows us to have a suitable notion of outlier in extreme cases such as when \\(\\diam(X\\setminus\\{x_0\\})   0\\).\n\nOur main theorem establishes that any stationary t-SNE output, \\textit{regardless of its input}, is incapable of depicting extreme outliers. , in the sense that the \\(\\alpha\\) number is bounded by a small constant. , in the sense that the \\(\\alpha\\) outlier measure of any stationary t-SNE output is upper-bounded by a small universal constant. We show this by analyzing the gradient on the outlier point. The following lemma will be useful. For simplicity, we work in one dimension, and we make the assumption that\n\n\n\\begin{figure}[t!]\n   \\centering\n\\includegraphics[width0.49\\linewidth]{./iclr2026/images/outlier_figs/illustrative_plot_.png}\n\\includegraphics[width\\linewidth]{images/outlier_figs/credit_card_full.png}\n   \\includegraphics[width\\linewidth]{images/outlier_figs/OUTLIER_MAIN1.png}\n\\includegraphics[width\\linewidth]{images/outlier_figs/OUTLIER_MAIN2.png}\n\\includegraphics[width0.707\\linewidth]{./iclr2026/images/outlier_figs/OUTLIER_REAL2.png}\n\\vspace{-0.15in}\n   \\caption{\n   \\small\n   t-SNE's versus PCA's response to \\(\\alpha\\)-outliers. Top row: on a dataset that tracks financial activity, around \\(1\\\\) of which is fraudulent, t-SNE fails while PCA largely succeeds at separating fraudulent (red) from non-fraudulent (black) points. Note that each of the fraudulent data points is an \\((\\alpha > 0)\\)-outlier with respect to the non-fraudulent group; the top right figure shows how t-SNE and PCA register those \\(\\alpha\\)-values in their output. Middle row: a similar analysis on a synthetic dataset comprised of a Gaussian sample plus a single $\\alpha$-outlier, with varying values of $\\alpha$. Bottom row: mixture of two Gaussians plus 1, 10, and 100 $\\alpha$-outliers. Despite a large gap ($\\alpha > 1$) between the outliers and the two clusters, t-SNE is unable to separate them.\n   In the t-SNE plots, the outliers are not separated   cluster structure, whereas in the PCA plots the outliers overtake the structure of the embedding. In the top row, we compare t-SNE and PCA's visualization of a dataset regarding credit card fraud detection; in particular, we plot \\(\\alpha(X,x_0)\\). In the middle row, we run a similar analysis on a synthetic data model of a set of Gaussian samples plus an outlier. \n   } \n   \\label{fig:outliers1}\n   \\vspace{-0.1in}\n\\end{figure}\n\n\n\n\n\\begin{restatable}{theorem}{OutlierAbs} \n\\label{thm:outlier_abs}\nFix \\(n > 2\\) \\todo{$n\\geq 2$ otherwise $\\rho$ is not defined.} we're actually woprking with n+1 points, so I updated rho. \nand \\(\\rho \\in (1,n-1)\\). Let \\(Y   \\{y_0, y_1,\\ldots,y_{n-1}\\} \\in {\\IMTSNE} \\) be a stationary t-SNE embedding. Without loss of generality let \\(y_0\\) be the outlier point. Then we have:\n\\[\\alpha(Y)   \\alpha(Y,y_0) \\leq \\sqrt{1 + \\Big(1 + \\frac{2}{n-2}\\Big) \\Big(\\frac{8}{1 + \\sum_{i1}^{n-1} P_{0|i}(X)}\\Big)}   3 + o(1)\\]\nfor all \\(X   \\{x_0, x_1,\\ldots,x_{n-1}\\}\\) such that \\(Y\\in \\TSNE_{\\rho}(X)\\).\nand \\(\\rho \\in [1,n]\\). Let \\(Y   \\{y_0, y_1,\\ldots,y_{n}\\} \\in {\\IMTSNE} \\) be a stationary t-SNE embedding. Without loss of generality let \\(y_0\\) be the outlier point. Then we have:\n\\[\\alpha(Y)   \\alpha(Y,y_0) \\leq \\sqrt{1 + \\Big(1 + \\frac{2}{n-1}\\Big) \\Big(\\frac{8}{1 + \\sum_{i1}^n P_{0|i}}\\Big)}   3 + o_n(1)\\]\nfor all \\(P(X)   P(\\{x_1,\\ldots,x_n\\})\\) such that \\(Y\\in \\TSNE_{\\rho}(X)\\).\n\\end{restatable}\n\nThe result is proven via analysis of the t-SNE gradient: we argue that if the outlier is too far away, its gradient is nonzero, thus violating stationarity. Key to this analysis is a comparison between the aggregate behavior of the outlier point's affinities in the input versus the output; in other words, the comparison between \\(\\sum_{i1}^{n-1} P_{i0}\\) and \\(\\sum_{i1}^{n-1} Q_{i0}\\). This is where the fundamental asymmetry of t-SNE comes in. While the latter is dependent on the position of the outlier point \\(y_0\\), per Lemma \\ref{lem:Qsum_bound}, the former has a lower bound of \\(1/(2n)\\) due to the normalization of the conditional affinity probabilities. \nThe key fact behind this result is the normalization of the \\(P\\) matrix. \n\n\nThe input-agnostic nature of this result is striking: even if the input is an extreme outlier configuration, a t-SNE output cannot depict its extremity past roughly \\(\\alpha   3\\). This behavior stands in stark contrast to that of principal component analysis (PCA), as shown in Figure \\ref{fig:outliers1} on both real and synthetic data models. PCA tends to preserve the \\(\\alpha\\) outlier number, while t-SNE seldom depicts outliers past \\(\\alpha > 0.2\\) in practice, and often depicts them as within the convex hull of the rest of the points (hence \\(\\alpha   0\\)). Furthermore, when faced with multiple outliers, (Figure \\ref{fig:outliers1}, bottom) t-SNE gracefully accommodates them into the global structure of the bulk of the data. We make this comparison in practice, where we find, somewhat strikingly, that \\(\\alpha\\) tends to hover quite close to \\(0\\). Visually, in the plots, outliers are often unnoticeable. The values of \\(\\alpha\\) we observe from t-SNE outputs hover well below \\(1\\)\n\nOur result suggests that t-SNE is an inappropriate tool to use in situations involving outlier detection. Consider, for instance, a dataset of financial transactions where the goal is to detect fraudulent user, studied by \\citet{dalpozzolo2015_calib}. In this dataset, only \\(0.172\\)\\ percent of the points ($492$ out of $284,807$) are fraudulent and by many standard statistical metrics register as outliers. Comparing the t-SNE and PCA plots on a   random representative subset of this data ($5050$ points, of which $50$ are fraudulent), we see that t-SNE mixes the frauds with the bulk of the points hides \\textcolor{red}{mixes?} the frauds\nwhile PCA keeps them separated for the most partdepicts most of them as far away \\textcolor{red}{keeps them separated?}\n, see Figure \\ref{fig:outliers1}, top row.\n\nFinally, note the distinction between t-SNE's muted response to outliers and its dramatic sensitivity to poison points. We illustrate this distinction on a dataset of BBC news articles \\citep{bbc_dataset}, see Figure \\ref{fig:outliers_real_world}. Given RoBERTa \\citep{liu2019roberta} sentence embeddings of these articles (\\(n2225, D1024\\)), we find that injecting $220$ poison points (see Appendix \\ref{sec:appendix_outliers_experiment} for the explicit construction) can halve the silhouette score of the t-SNE embedding with respect to the ground-truth labelling, whereas injecting $1100$ large-$\\alpha$-outliers slightly improves the silhouette score. Figure \\ref{fig:bbc_appendix}.\\textcolor{red}{refer to fig 5? cite bbc dataset?}\n\n\n\\begin{theorem}\n   For all \\(\\alpha> 1\\), there exists a perplexity \\(\\rho\\) and a dataset \\(X_\\alpha\\) which is an \\((\\alpha, x_0)\\)-outlier configuration with affinity matrix \\( PP_\\rho(X_\\alpha)\\) such that   \\[\\]\n\\end{theorem}\n\n\n\n\n\\begin{figure}\n   \\centering\n   \\includegraphics[width0.283\\linewidth]{./iclr2026/images/outlier_figs/OUTLIER_REAL1.png}\n\\includegraphics[width\\linewidth]{images/BBC_POISON.png}\n\\vspace{-0.15in}\n   \\caption{   \\small\n\\textcolor{red}{FIX CAPTION} \nt-SNE's response to the injection of poison points (middle) and $\\alpha$-outliers (right) on the BBC News Article dataset. Middle: injecting poison points (red) to the original dataset (black) significantly disrupts the underlying cluster structure. Right: while injecting $(\\alpha > 1)$-outliers (red) does not disrupt the underlying cluster structure (black), the extreme outliers themselves are not well separated. The bottom left label in each plot denotes silhouette score of the t-SNE projected original points (without the injected points) with respect to the true labels (business, entertainment, politics, sport, tech).   Outlier behavior on real-world data. Left: given data monitoring financial activity (\\(n5050\\), \\(D30\\)) where one percent of users are committing fraud, PCA succeeds and t-SNE fails in visualizing the frauds as outliers. Right: using RoBERTa transformer embeddings of BBC news article titles (\\(n1191, D768\\)), we find that its t-SNE clustering can be destroyed by injecting a relatively small number of ``poison'' points; meanwhile, the clustering structure is remarkably robust to the injection of faraway \\((\\alpha\\gg 1)\\)-outliers\n}\n   \\label{fig:outliers_real_world}\n\\vspace{-0.1in}\n\\end{figure}\n\n\n\n\n\n\n\n\n",
  "title": "t-SNE exaggerates clusters, provably"
}
