{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:JAX version 0.7.2 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from /Users/Akseldkw/coding/Columbia/UML-Project/.env.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:arviz.preview:arviz_base not installed\n",
      "INFO:arviz.preview:arviz_stats not installed\n",
      "INFO:arviz.preview:arviz_plots not installed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Akseldkw/coding/kretsinger/data/nb_log.log\n"
     ]
    }
   ],
   "source": [
    "from kret_studies import *\n",
    "from kret_studies.notebook import *\n",
    "from kret_studies.complex import *\n",
    "\n",
    "logger = get_notebook_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/Users/Akseldkw/coding/Columbia/UML-Project/data/huggingface'),\n",
       " PosixPath('/Users/Akseldkw/coding/Columbia/UML-Project/data/huggingface/REGISTRY.json'),\n",
       " device(type='mps'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uml_project import *\n",
    "\n",
    "HF_DIR, HF_REGISTRY, DEVICE_TORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_DIR = HF_DIR / \"imdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb_train = pd.read_parquet(IMDB_DIR / \"train.parquet\")\n",
    "df_imdb_test = pd.read_parquet(IMDB_DIR / \"test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_imdb_train\n",
    "test_df = df_imdb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stsb_dict = load_dataset(\"glue\", \"stsb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stsb_train: pd.DataFrame = stsb_dict[\"train\"].to_pandas()  # type: ignore\n",
    "df_stsb_val: pd.DataFrame = stsb_dict[\"validation\"].to_pandas()  # type: ignore\n",
    "df_stsb_test: pd.DataFrame = stsb_dict[\"test\"].to_pandas()  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stsb_train.sort_values(\"label\", ascending=False)\n",
    "# df_stsb_val.sort_values(\"label\", ascending=False)\n",
    "# df_stsb_test.sort_values(\"label\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(huggingface_hub.list_datasets(dataset_name=\"stsb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb = models.Transformer(\"bert-base-uncased\")\n",
    "pooling = models.Pooling(word_emb.get_word_embedding_dimension(), pooling_mode_mean_tokens=True)\n",
    "dense = models.Dense(\n",
    "    in_features=word_emb.get_word_embedding_dimension(), out_features=128, activation_function=torch.nn.Tanh()\n",
    ")\n",
    "\n",
    "model = SentenceTransformer(modules=[word_emb, pooling, dense])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # ABOBA: small, fast\n",
    "TARGET_DIM = 64  # ABOBA desired embedding dimensionality (experiment with 32,\n",
    "# 64, 128...)\n",
    "BATCH_SIZE = 64\n",
    "POOLER_LR = 2e-4\n",
    "FINETUNE_LR = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_POOLER = 2  # step A epochs (pooler only)\n",
    "EPOCHS_FINETUNE = 2  # step B epochs (unfreeze and train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(base_model_name: str, target_dim: int):\n",
    "    \"\"\"\n",
    "    Build a SentenceTransformer where we append a Dense projection after pooling\n",
    "    to obtain exactly `target_dim` output dimensions.\n",
    "    \"\"\"\n",
    "    # Transformer (encoder)\n",
    "    word_embedding_model = models.Transformer(base_model_name, max_seq_length=128)\n",
    "    # Mean pooling (or use cls pooling if you prefer)\n",
    "    pooling_model = models.Pooling(\n",
    "        word_embedding_model.get_word_embedding_dimension(),\n",
    "        pooling_mode_mean_tokens=True,  # sentence embedding = mean of word\n",
    "        # ↪embeddings in sentence, that's rule of thumb for sentence similarity but if\n",
    "        # ↪we want to do classification prob cls is better\n",
    "        pooling_mode_cls_token=False,  # instead of cls or max use mean here;\n",
    "        # ABOBA: can vary and see changes\n",
    "        pooling_mode_max_tokens=False,\n",
    "    )\n",
    "    # The pooler (projector)\n",
    "    dense = models.Dense(\n",
    "        in_features=pooling_model.get_sentence_embedding_dimension(),\n",
    "        out_features=target_dim,\n",
    "        activation_function=nn.Tanh(),\n",
    "    )\n",
    "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense], device=DEVICE)  # type: ignore\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pooler_then_finetune(model: SentenceTransformer, train_examples, val_examples, out_dir: str):\n",
    "    # Step A: train pooler only (encoder frozen)\n",
    "    uml_utils.freeze_encoder_only(model)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_examples, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    # Use CosineSimilarityLoss for contrastive-style or MSELoss for regression\n",
    "    # (STS)\n",
    "    loss_fct = losses.MultipleNegativesRankingLoss(model)\n",
    "    evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "        val_examples, name=\"sts-val\"\n",
    "    )  # note this benchmark compares against human-annotated similarity scores;\n",
    "    # ABOBA: we can't self-annotate sim for Swift or Verma so we can't get\n",
    "    # encoder error\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, loss_fct)],\n",
    "        evaluator=evaluator,\n",
    "        epochs=EPOCHS_POOLER,\n",
    "        warmup_steps=100,\n",
    "        output_path=os.path.join(out_dir, \"stepA_pooler_only\"),\n",
    "        optimizer_params={\"lr\": POOLER_LR},\n",
    "    )\n",
    "    # Step B: unfreeze encoder and finetune whole model\n",
    "    uks_torch.unfreeze_model_weights(model)\n",
    "    # Recreate dataloader (sentence-transformers expects InputExamples in an\n",
    "    # in-memory list)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_examples, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    loss_fct2 = losses.MultipleNegativesRankingLoss(\n",
    "        model\n",
    "    )  # good objective for contrastive training (requires positive pairs)\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, loss_fct2)],\n",
    "        evaluator=evaluator,\n",
    "        epochs=EPOCHS_FINETUNE,\n",
    "        warmup_steps=100,\n",
    "        output_path=os.path.join(out_dir, \"stepB_finetune\"),\n",
    "        optimizer_params={\"lr\": FINETUNE_LR},\n",
    "    )\n",
    "    # -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375b7878f7e74ecb930a7da8e0626e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41073d425e094db6ac7aea3ae7b28ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23023c74c37b401cb42c9a484ce3ee06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2560f39b0d514491b517191ba237843d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537c982a4b5f419091cd7e386be5a69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b811c641170e4f9a99be3955486d6c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s_model = build_model(BASE_MODEL, TARGET_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Dense({'in_features': 384, 'out_features': 64, 'bias': True, 'activation_function': 'torch.nn.modules.activation.Tanh'})\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'texts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_pooler_then_finetune\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_stsb_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_stsb_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput/sentence_transformer_finetuned\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mtrain_pooler_then_finetune\u001b[39m\u001b[34m(model, train_examples, val_examples, out_dir)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Use CosineSimilarityLoss for contrastive-style or MSELoss for regression\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# (STS)\u001b[39;00m\n\u001b[32m      7\u001b[39m loss_fct = losses.CosineSimilarityLoss(model)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m evaluator = \u001b[43mevaluation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingSimilarityEvaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_input_examples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msts-val\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# note this benchmark compares against human-annotated similarity scores;\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# ABOBA: we can't self-annotate sim for Swift or Verma so we can't get\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# encoder error\u001b[39;00m\n\u001b[32m     13\u001b[39m model.fit(\n\u001b[32m     14\u001b[39m     train_objectives=[(train_dataloader, loss_fct)],\n\u001b[32m     15\u001b[39m     evaluator=evaluator,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     optimizer_params={\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: POOLER_LR},\n\u001b[32m     20\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/kret_312/lib/python3.12/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:148\u001b[39m, in \u001b[36mEmbeddingSimilarityEvaluator.from_input_examples\u001b[39m\u001b[34m(cls, examples, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m scores = []\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m examples:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     sentences1.append(\u001b[43mexample\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtexts\u001b[49m[\u001b[32m0\u001b[39m])\n\u001b[32m    149\u001b[39m     sentences2.append(example.texts[\u001b[32m1\u001b[39m])\n\u001b[32m    150\u001b[39m     scores.append(example.label)\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'texts'"
     ]
    }
   ],
   "source": [
    "train_pooler_then_finetune(s_model, df_stsb_train, df_stsb_val, out_dir=\"output/sentence_transformer_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kret_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
